\documentclass{UoYCSproject}
\author{Harry Burge}
\title{Swarm Memory}
\date{Version 1.0, 2020-November}
\supervisor{Simon O'Keefe}
\MEng

\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\dedication{}

\acknowledgements{
 
}

% More definitions & declarations in example.ldf

\begin{document}
\pagenumbering{roman}
\maketitle
\listoffigures
\listoftables

\bibliographystyle{ieeetr}
%\renewcommand*{\lstlistlistingname}{List of Listings}
%\lstlistoflistings

%%%% Executive Summary %%%%
\begin{summary}

\end{summary}
%%%%%%%%%%%%%%%%%


%%%% Itntroduction %%%%
\chapter{Literature Review}
\label{cha:Literature Review}

\section{Introduction}
\label{sec:Introduction}

Swarms are an increasingly important area of research for society, as the world moves towards a distributed technology future. 
The research of swarms within a technology setting can be broadly divided into two partitions, these are intelligence and mechanics. 

Swarm intelligence can be viewed as the research into highly distributed problem solving\cite{Cognitive maps mine detection, Swarm intellegiegence}. 
This is ever more becoming relevant as computer systems start to level out in sequential performance \cite{CPU speed} and parallelism is embraced, satisfying the demand of the age of big data \cite{Avalability storage}.

Swarm mechanics heads more down the robotics side and can be seen as the study of practical implementation of swarms, whether that be movement or communication within the swarm.
This is on the rise in the industry, as society's pace increases and manual labor is automated out, whether its drone delivery to inpatient customers or mapping areas in dangerous environments \cite{Swarm robotics reviewed}.

These two areas often are highly integrated rather than being disjoint from each other, and are rarely seen in their pure form. 
An example of a pure form of swarm intelligence can be seen in \cite{Swarm intellegiegence} with network routing protocols. 
This project will be focusing mainly within said grey area, but predominantly in intelligence dealing with a practical problem.

Focusing down on distributed and local memory of swarm-like agents, that will be covered by this project. 
Most research has gone down the route of optimization on distributed problem-solving algorithms, as compared to practical applications of storage of abstract ideas as a collective. 
As one of the key reasons for using a swarm is redundancy, which is often assumed and boasted about, rather than proven specifically within the memory domain.

This relative lack of research into collective memory, seems to this author to be a glaring hole in the foundations of a complex and interchangeable subject. 
The need for more research into collective memory can be seen in how invaluable it would be to applications like mapping of a dangerous area \cite{Cognitive maps mine detection}. 
By being able to handle the loss of agents and the collection of data on agents with limited memory, we could ensure efficient solutions that have high redundancy compared to other implementations.

An explanation for swarm based memory management solutions to be a less developed area of study is the existence of subjects like cloud-based and raid based storage systems. 
The argument for having these two subjects partially-separated is due to the nature of a swarm's locality and ever-changing network style, compared to a server farm. 
Storage of data on an ever-changing network of devices is a hard task to complete, handling loss of connection between servers, reliability to access of the data and loss of services, whether it be non-correlated or correlated failures \cite{Avalability storage}.

Most elements of cloud storage policies at a high level of abstraction could work effectively within a swarm based environment. 
However as explained above, key adoptions would need to be changed to create said effective policy. 
A prime example of the type of algorithm is “SKUTE” from \cite{Distributed Storage}.
“SKUTE” will be the main inspiration for this project's solution, too storage on a highly dynamic network.

The objective of this dissertation is to merge three areas of study into an effective/suitable storage policy for swarm-like agents in a setting with high locality and dynamic connection behaviours. 
Then to perform multiple analyses on the created policy using a variety of simulations to gauge its capability compared to the desired abstract behaviour.

To complete the objective of this report we will programmatically break down the problem described in Section \ref{sec:Problem} into solvable tasks. 
Therefore the report will be structured as follows, firstly we’ll define a clear and concise problem, of which incompaces all disgruntlements described above. 
Secondly, bring the reader up to date with relevant literature and explain key concepts that will be required for a complete understanding of where the proposed solution has been derived and why said solution might be a relevant stepping stone for future research. 
This will be covered in the two sections, Section \ref{sec:Cloud} of which goes into detail about current cloud based storage technologies and Section \ref{sec:Robotics} of which will delve into more of a background behind swarms, specifically relating to the problem and possible solutions. 
We’ll then go through the methodology of the proposed solution’s design.
How it is supposed to act and react in different scenarios, and the reasons for why. 
This leads to analysing how effective the proposed policy has kept to standards derived in the methodology section, and whether it solves the problem defined in Section \ref{sec:Problem}.

%%%%%%%%%%%%%%%%%%

%%%% Problem Definition %%%%
\section{The Problem}
\label{sec:Problem}

The problem this report will cover is defined as follows. 
We need to create a storage policy for agents of a swarm, to be able store directional abstract data as a collective, without complete duplication.

This problem can be split into two separate sub-problems. 
One is the handling of data duplication throughout the swarm as to be able to control for failures of agents, and provide a mechanic for recovery from said failures. 

\begin{figure}[htb]
\label{fig:popdensity}
\begin{center}
\centering
\includegraphics[width=\linewidth]{"./ExplanationImgs/Memory_Pop_Density.png"}
\caption{Data duplication density based off distance to datas desired location}
\end{center}
\end{figure}

The second is controlling where the duplicated data is within a world compared to where the data is needed in that world. 
A visualization of this can be seen in Figure \ref{fig:popdensity}, this shows the density of duplications within an area based on distance from the desired position of that data. 
As the reader can see the further we get from the desired point we should have less duplicates of data compared to agents without duplications of that data.

There are lots of examples where a problem like this could arise, a good example of where this could be applied is operating in a mine filed \cite{Cognitive maps mine detection}. 
Near the start of the agents operation they will need to map out where potential mines might be and record their location. 
Obviously once an agent finds a mine we would want it to spread the word of the location of said mine. 
However due to memory restrictions the agents can only know about a minimal amount of mines, therefore agents closer to the mine should prioritize knowing its whereabouts compared to mines it may never come across. 
Now bringing this into a more of a practical solution if agents fail individually for example running out of battery, or as a group from a mine going off. 
We still need the swarm to not lose data, in the case of our example it would still be relevant to know where a possible crater could be.

With this increase in complexity, the storage policy needs to be able to withstand the fluctuations and locality of the swarm. 
With reliable redundancy to handle correlated (Mine detonation) and non-correlated (Power loss) failures.


%%%%%%%%%%%%%%%%%

%%%% Litreture Review %%%%

\section{Cloud/Backup storage policys/schemes}
\label{sec:Cloud}

Like most things in computer science, cloud storage started off relatively simple (In nowadays terms). As the years have progressed so has the demand and use of the cloud, varying from everyday people storing files to large businesses storing harvested data. This led to the need for much sophisticated storage solutions, which can handle the increasing file size and frequency of use. A component that increased this complexity was the Legal Services Act. 2007 \cite{LSA}. This enforces that cloud storage suppliers must provide reliable and fast data collection for users. Not only that but to also provide near guaranteed longevity of stored data. In this section we will focus on cloud-based storage policies and some background terminology needed for this report.

Firstly the reader will need to understand the difference between correlated and non-correlated failures. A non-correlated failure is when a device fails independently and with no relation to other failures with the system as a whole. An example of this within cloud based computing, a server node can shut down due to a software failure, therefore we lose connection and access to the node’s data, typically this is completely independent of other servers in the rack. A correlated failure as the name suggests, is when a device fails with other devices with relation linking why they have failed. A typical example of this in cloud computing would be mass restarts because of a power surge from a storm. The power surge event is what links the failures together, therefore making it correlated. To be correlated doesn't mean they need to be geographically close together, however within our swarm solution will mean geographically close failures. 

To control for these two types of failures there are many different solutions providing different features. Locally what is typically used is a RAID system for local failures within a node, and then a replication policy \cite{Avalability storage} for internode duplication. These in tandem provide stable node storage and redundancy for when a possible node failure acquires.

The most common forms of replication policies will take a piece of data, decide whether the data needs to be duplicated and if so will completely copy the data onto another storage device. This provides a backup in case of failure on either one of those devices. A simplistic approach would be a random replication policy, where data is randomly chosen to be duplicated, typically duplicated within the same datacenter, so on a neighboring rack. This is an efficient design policy for handling non-correlated errors, however, lacks the robustness against correlated errors, and without a tracking of global duplications can lead to over used storage. We can mitigate for correlated errors by allowing for duplications to happen over data centers, however, this leads to downsides which will be explained below. An algorithm like random replication, is substantial for long-term storage where popularity of data and distance to users are averagely the same for all data items.

Two key concepts of availability and popularity are not taken into account when using a random replication policy. When cloud based storage transitioned from a semi-local backup system to a worldwide daily driver. Random replication can’t withstand the variability of how users interact with files nowadays. An example of why these concepts are needed in today's age, are videos. If a video is hosted in one country and replicated within said country then international viewers might have delays to their streaming. If we then tried to compensate for that by hosting it in multiple countries, those other countries might not view the video as much. This therefore means we are wasting storage space of which we could use for other more popular videos. This therefore leaves us trying to maximise for both situations, and a new replication policy is required.

We will be looking into two different algorithm concepts, of which try to handle the maximisation problem. Both withstand non-correlated failures well because of the nature of replication, so we will only be looking into the other effects. The algorithms have been abstracted from papers on handling "Distributed key-value store" \cite{Key-Value}, where you have key-value pairs on multiple devices on a network where duplication only leads to more fault tolerance of the data stored.

The first approach uses a privileged level of control where it uses its global knowledge to make decisions about whether and how to duplicate items \cite{Avalability storage, Patent}. This doesn’t have to just be data replication, but the same principles can be seen within schema changes \cite{Scheme changes}. Due to the nature of having a privileged user, the control of the policy is a lot easier to make specific behaviours be exhibited and to be understood. This means we have higher guarantees for correlated failures unless on the master node, however this can be handled dynamically by assigning another master, touched upon in Section \ref{sec:Robotics}. Availability and popularity are handled by the policy coded onto the master node.

Having an approach that uses a master, doesn’t work effectively for a swarm. This is because the change from a server network to a swarm is quite a drastic change. Servers running over network generally have complete connectivity e.g. Global scope. Also servers have a constant power supply compared to the average swarm agent. When restricting the masters scope we have to rely on messages over other agents which will first of all reduce processing capability and power loss will be more significant to agents closer to the master, possible leading to a cut off from command \cite{Swarm robotics reviewed}. It also doesn’t fit into the ideology of a swarm, this will be talked about in Section \ref{sec:Robotics}.

The second approach doesn’t rely on a privileged member and can be adapted for locality. We follow a distributed control approach where each node (In the case described below its each key-value pair) has its own controller. Following the approach used with “SKUTE” as proposed in \cite{Distributed Storage}, it can make four decisions per data item. These decisions are; Migration, Suicide, Replication, and Nothing.

Migration is the move to a lower cost or more redundant servers. Suicide is the removal of itself, this is usally be because of to many duplicates. Replication is when the data decides that it needs to be duplicated and sent to another node and Nothing is as the name indicates.

Because of the highly distributed nature of said approach, when coming to suicide we need to handle the edge case where the only two nodes with duplicates make the decision to suicide at the same time, therefore leaving us with no replications. This is where a consensus algorithm comes into play. Paxos \cite{Paxos} is an example of how both nodes couldn’t suicide at the same time, therefore leading to the ideal case in this example of only one duplicate. 

Within the domain of server storage networks an approach like “SKUTE” is less commonly used because it adds complexity which is not needed within a global and consistently powered network. Most data warehouses would prefer to have one server running as a controller and other servers running at full capacity compared to all servers at a slightly lower capacity due to extra self computation. However this approach allows for greater redundancy because of having no single point of failure.

An approach like this is highly adaptable towards a homogeneous swarm. However with heterogeneous swarms the previous algorithm may work a lot better. Differences between the swarm types will be explained in Section \ref{sec:Robotics}. 

Moving towards local redundancy and optimisation is the stagnated study of RAID. This is where we change orderings of multiple storage discs to gain redundancy and/or performance increases. This grouping of disks is called a RAID array and can be structured in a multitude of ways. Common structures are labelled as RAID levels and give different attributes based on what functionality you are pursuing \cite{RAID Levels}. 

One of the key components of multiple RAID levels is the use of parities \cite{Raid parity}. This is where a function (typically an XOR) is done on two or more sets of data to create one or more parities. The function has a property thus that if a tolerant amount of disks are lost the data that was lost can be reconstructed. In the case of data A, data B and A XOR B, if data B is lost then can be reconstructed using data A and A XOR B. With different levels and functions more than one disk can fail and still retain data however if failures go over that then all data is lost. RAID is predominantly used internally within a storage node to provide redundancy against disk failures and increase speed of writes that are typically on hard disks, because of cost and possible reads after failure of heads. 

The methodology is that as long as the nodes individually are redundant enough and then there is control on a higher level with our replication schemes, that is a sufficient redundancy. RAID could be adapted to run over multiple different storage nodes, however the complexity compared to performance is heavily in the favour for the above methodology for storage networks. We will come back to the possible uses of RAID internally and externally in Section {Improvements}.

// Finish rewriting
// improvements refrence


\section{Swarm robotics}
\label{sec:Robotics}

As explained in the introduction, the study of swarms are split into two subsections, mechanics and intelligence. Both explained broadly in the Section \ref{sec:Introduction}. 

Continuing on the discussion about swarm intelligence. Typically swarm intelligence focuses on solving abstract problems, like the traveling salesman problem, in a local distributed manner compared to a global manner. From the papers read by the author, it seems that predominantly the topics undertaken are testing distributed solvers compared to already researched solutions to see how they measure up. An example of this within the TSP domain is a genetic algorithm versus AS-TSP \cite{Swarm intellegiegence}. These algorithms provide benefits and drawbacks compared to their counterparts.

The concept of swarm intelligence is creating a solver to a problem using a distributed algorithm that can rely on natural parallelism, doesn't rely on global knowledge and is adaptable on the fly, compared to their counterparts. A good example of where these algorithms excel is the networking domain, because of the high parallelism and need for adaptability \cite{Swarm intellegiegence}.

The other subsection can be broadly known as swarm mechanics. This encompasses all of which swarm intelligence doesn’t cover. Swarm mechanics focuses on problems that are less abstract and are usually in the domain of physical implementation \cite{Cognitive maps mine detection, Probabalitic automata foraging robots}. Swarm robotics can be seen as the same as swarm mechanics, however, it doesn’t have a broad enough scope/name to fit everything that can be researched in this author's opinion.

Two arguments to justify the naming of swarm mechanics are as follows; within this domain we focus on the emergent behaviour of a swarm compared to the solution it might give. The second is that swarm robotics doesn’t encompass the study of swarm behaviour in nature \cite{Swarm intellegiegence, Ant communication}.

Delving deeper into swarm robotics we have three different methodologies, heterogeneous, homogeneous and hybrid \cite{Swarm robotics reviewed}. These can be adopted in multiple ways, however, we will focus upon the adoption of these methodologies on decision making and physical attributes of agents. Firstly we will talk about the physical adoptions.

\begin{figure}[htb]
\begin{center}
\label{fig:anthero}
\includegraphics[height=4cm]{"./ExplanationImgs/AntHetro.png"}
\end{center}
\caption{Example of a hetrogenus ant colony. https://www.pinterest.co.uk/pin/777363585651532845/}
\end{figure}

A heterogeneous swarm is defined by having differences between agents of the same swarm, as in Figure \ref{fig:anthero}, whether physical or mental \cite{Swarm robotics reviewed, Swarm intellegiegence}. These occur commonly in nature and are less studied \cite{Swarm intellegiegence}, because differences in agents are a rarely needed property in research-based problems. For real-world solutions, heterogeneous swarms can be of great use, allowing other agents to pick up the slack of the swarm, or complete tasks that other swarm members cannot complete. A good example as described in \cite{Swarm robotics reviewed} with a mother ship being a navy boat and a swarm of quadcopters. The boat picks up for the slack of the swarm by being able to transport them longer distances than the swarm could normally cope with.

The argument against heterogeneous swarms is that there is a tendency to over rely on the differences of agents. Running with the example from \cite{Swarm robotics reviewed}, the agents rely on the naval boat to be able travel longer distances and have to have a recharge point. Without the boat the swarm fails after some time. The decision to have a heterogeneous swarm in this case is valid because if the naval ship is lost, then something has already gone horrendously wrong.

To have physical differences in agents, is to breed efficiency. However this can only hold true if the vulnerability of losing too many agents of the same type, that’s work is key to the survival of the swarm, is mitigated. This vulnerability can be controlled for in multiple ways. Common rules are found in nature's swarms and can be extracted from them. These are; jobs need to be either interchangeable between all types of agents however some agents are more efficient at that job \cite{Ant communication} or the jobs that are specific need to be non-essential for the colony's survival. 

Ants typically fit into this category where ants have different types, as shown in Figure \ref{fig:anthero}. Some ant species, like Leaf-Cutter Ants, even have subcategories within a category of type. Leaf-Cutters have workers that will specialise in certain tasks like fungus farming. The best example of showing the interchangeability of these roles is when major ants do worker jobs when there is a significant loss of workers \cite{Swarm intellegiegence}. This leads us more towards a hybrid approach which is explained later on in this section.

Because practical implementations of what humans can achieve currently in their robots, they don’t have the adaptability that biology can provide, without making agents too complex.

Homogeneous swarms are defined by each agent being the same. This is found less often in nature, except for at the microbial level, and is commonly found in man-made agents. Because of biology's natural adaptability compared to current standards of robotics, semi-heterogeneous swarms are exploited better \cite{Swarm robotics reviewed, Swarm intellegiegence}. Therefore we maximise for the floors of our current technology, however with a sufficiently complex agent homogeneous swarms are the most optimal, but that is getting into speculative futuristic technologies of self replication, advanced intelligence and nano size.

Homogeneous swarms benefit from maximum redundancy, this is because if any agent goes down there are still an entire swarm's worth of agents to take its place. With this benefit of redundancy we acquire some possible losses in efficiency which could have been exploited with agents with specific hardware. The design for homogeneous agents is a complex one, either the agent is too simplistic therefore loses efficiency in their tasks. Or they are too over engineered to the point that all agents have the ability for every specialism and may never need said hardware. There is a thin line between the two, where either we lose practical power of the swarm or we have to invest more into the swarm than it actually needs. An example to show this dynamic is if we have agents that need to mine and farm, they all have hands so can do the task at a suboptimal speed. We then as an improvement give them picks and hoes instead of arms. This gives us an increase in mining and planting speed, but why would the miners need a hoe.

Within the practical implementation of swarms, everything gets a bit messy. Usually there is not a clear cut framework or design that a swarm is designed to be like. They are designed to be as efficient as we can make them to be in any type of problem faced, this is where research and engineering have a bit of a disconnect. This is where hybrid approaches come into their own.

A hybrid approach tries to exploit the benefits of both heterogeneous and homogeneous designs without the downsides. Carrying on from our example of farmer and miner swarms, a hybrid approach to the physicality of an agent would go something like as follows. Each agent would have exactly the same body and could wield either a pickaxe or a hoe, but the key point is that a miner could become a farmer if it was required. The reader might wonder why physical hybrid approaches aren’t regarded as the best of all approaches. This is because when bringing a theoretical solution into the real-world we gain massive complexities. How can we guarantee job type distribution? What about the complexity of changing between job type hardware? These are all questions that are needed to be explored by the person creating the hybrid swarm. Usually it is easier to go for the simpler solution and deal with the possible loss of either efficiency or adaptability.

Moving on to the control/decision making of a swarm following these approaches. Homogeneous control follows the purest form of swarm robotics, where each agent has control of its own decision making based on what other agents in its locality are doing, sometimes labbelled distributed intelligence. This therefore creates an emergent/structured behaviour of the swarm even though each agent is acting of its own fruition and can usually only see locally. A simple example of this is \cite{Boids}.

Heterogeneous control is also very simple in nature, where certain agents control other agents' decision making. This can be handled in multiple ways, two promoniante ways are hivemind control \cite{HiveMind} and royalty/hierarchical control. Hivemind is where one agent controls the entire swarms decision making e.g. The hivemind controller will say the swarm needs to move to the left and then the agents handle that the way it decides. In a hierarchical approach it follows the same style as hive mind however deals with scalability better. Where we somehow have a power structure of certain agents being sub leaders of leaders. This control structure leaves itself vulnerable in the same way as its physical implementation, however, also has the fear of bad actors and power loss distributions over the swarm. These still can affect homogeneous swarms however is less of a threat than on a heterogeneous controlled swarm.

Hybrid approaches to control of a swarm are just heterogeneous control policies that can adapt to changes of leaders and are usually designed for homogenous/hybrid swarms. The choice of leader(s) is usually done through a consensus algorithm \cite{Paxos} rather than based on any form of physical or mental difference. This allows for homogenous style bots to act in heterogeneous fashion. This can create more deterministic behaviours compared to emergent behaviors of homogeneous control, and can also help with the power loss distribution problem by re-electing leaders in different locations to help distribute where messages are relayed.

Humans themselves are a great example of a fully hybrid based swarm both in design and communication. Though humans have variations in characteristics they can be seen as pretty homogeneous in terms of the tasks that they can perform, obviously removing edge case actions like child birth. Tools and knowledge can be spread between humans to make the swarm more efficient and an agent can specialize in a certain area. However, if some agents are lost other agents can replace them by using the same tools and knowledge from the remaining agents of that specialism. Also, the natural power-based structure of humans fits a hybrid model in terms of electorship of some kind, and not of genetics (Except with royalty, however, this is more of a label rather than a genetic difference). The leaders aren't needed for every single action so fit into a usually hierarchical power structure, compared to something of a hivemind model.
%%%%%%%%%%%%%%%%


%%%% Motivations %%%%
\section{Motivation}
\label{Motivation}

As described above in Chapter \ref{cha:Literature Review} it is quite clear that swarm robotics is becoming and already is a soloution to many problems currently faced and going on into the future.
With indurvidual speeds of computers stagnating \cite{CPU speed}, the world becoming more data oreintated and the drive for humans to explore, distributed technologys need to rise to the challenge.
The next big step in computer science history being quatum computers, not solving the sequentail issues of our current problem solving algorithms.
This is why swarm robotics/intellegince needs to brought to the for front of research.

In our day and age there doesn't seem to be much use of these innovative works, possibly due to the complexity or to the newness of said subject.
The main applications nowadays are surevailence \cite{UAV, HiveMind} and delievery, however looking into the future, which we need to do otherwise we delay technological breakthroughs further, we can see that their are so many other uses for this type of distributed thinking.
Whether it be pyshically with robots, like in space exploration \cite{Space exploration}, nano-robot medicene or military based applications.
Or even conceptually like algortihms that can rely more on parrellel computation compared to their global sequentail counterparts.
A good example of this distributed thinking changing and revolotionising our subject is block chain \cite{blockchainandSwarm}.

It is for this reseon that I have decided to contribute my part to this extensive and breakthrough field.
%%%%%%%%%%%%%


%%%% Methodology/Design Chapter %%%%
\chapter{Main}
\label{cha:Main}



\section{Simulation Infomation}
\label{sec:Sim Info}

The base simulation that the policys will be running on is a specified.
There will be an area of which agents can move around, each point within that area can have a peice of data learned in that area.
When a peice of data is learned in that area , the data stores where is was created and the policys will take that starting place into account.
This is how we have defined our directional data aspect to the simulation, in real life this could be something like a learnt behavoiur that is needed for that specifc enviroment, however, for test purposes it is just a string.

Each agent has two bounded partitions of memory, these are called private and public memory.
Private memory is for knowledge that is learnt by that agent, and public memory is infomation that that agent has learned from other agents.
Both public and private memory cannot have duplicate data inside including across partitions.
This split was made arbitraraly and isn't needed for a practical soloution however was created due to agents being more likely to pick up learned data by not having to delete infomation in memory to make space for said leanred infomation.
In general public memory should be larger in size than private memory due to there being magnitudes more public infomation compared to private infomation for an agent.

Agents are homogenus, and have the same connection radius of which they can talk to other agents within.
Agents are assumed to be able to recieve and send packets whilst also doing actions like sending and recieveing itself, in real world soloutions this would likely be that each agent would need two recivers and senders or a control algortihm to handle this type of behavouir.
In this simulation we assume that data transfer is perfect.

Each agent moves randomly in circles varying in shapes and sizes to gain a swarm like movement of connections being broken and reconnected.
Agents our running in diffrent threads so run at diffrent speeds and acts more like a real world swarm.
Data is introduced at the start based of an amount wanted, and during the simulation data can be learned based an amount wanted.

\begin{figure}[htb]
\label{fig:Connarea}
\begin{center}
\centering
\includegraphics[width=\linewidth]{"./ExplanationImgs/Connarea.png"}
\caption{Example of simulation looks when running}
\end{center}
\end{figure}

In Figure \ref{fig:Connarea} we can see an example of what the 2D simulation looks like.
Dots are agents, and the red circle around them are their connection radius of which they can talk to other agents, these are usally omitted from being draw due to making the images messyer and harder to understand.
The blue consentic circles are a positional datas stages of allowed duplications, this is explained more in Section \ref{sec:Simple1}.
The connection lines between the agents are just showing that data can pass between these two agents, these lines change colour based of what frames are being passed across them, this will be touched upon more in specific examples due to colours meaning diffrent things.
As a simple visuallisation of how data is being passed between the agents, in this example the agent is blue signifiying that it holds the duplicate of blue data, e.g. the consetric circle.



\section{Simple Scattered Memory Policy}
\label{sec:Simple1}

Taking on from the design of algorithm presented in \cite{Distributed Storage}, I applied a simple distributed storage policy onto a swarm that takes into account positional data.
This policy has two actions that it can perform, suicide and replication, suicide is when a piece of data decides using a heuristic that it is not worth being stored in an agents memory so deletes itself, replication is where based on a heuristic the data believes it is worth spreading the infomation so will replicate to one member of the swarm.

\begin{figure}[htb]
\label{fig:Heuristic}
\begin{center}
\centering
\includegraphics[height=5cm]{"./ExplanationImgs/Heuristic.png"}
\caption{Poistional data heuristic for agents}
\end{center}
\end{figure}

The heuristic mentioned above follows these rules, and Figure \ref{fig:Heuristic} helps visuallise the conecept. 
At the grey agent in the middle is an example of when the data is learned, when learned this data will have a poistion that it was learned a radius at which you want the allowed duplications (including own duplicate) of that data to be one.
The red line signifys that distance and the value in this example four is the maximum duplications of that data.
The green line is just an easy way to compute which band an agent might be in.

As an agent moves closer through the gradient of allowed duplicates it will want to have more duplicates in its area, therefore allowing for a higher concentration of said duplicated data in that area.
We can then use this simple heuristic per item of data to be able to get the distribution that we want, one implementation of this is described below in Algorithm \ref{Agent_Control_Loop}.
The reason for having a random replication when the allowed duplications equal the actual duplications is to try and breakthrough the boudarys at the edge where allowed dupes equals 1.

Without this replication we would have data sit inside the data area to much, this can be seen on some prilimany test results Figure \ref{fig:Data1} and Figure \ref{fig:Data2}.
Blue line is amount of agents with that duplicated data.
Purple line is the mean distance of agents with duplicated data from the data point, Green area is the standard deviation and yellow/orange is the data range.
A guassian filter has been passed over the results due to the mild fluctions every iteration creating a harder to see results.

From the results shown in Figure \ref{fig:Data1} we can see that the distance from the area point likes to stay within side the data\_radius bounds, this was tested on diffrent sizes of data radius and max duplications allowed and still found to hold true.
We then tested the algorithm which has a random replication value to be able to try push through the borders of the data radius.
We ran these on two diffrent values of replication value for five times on each, Figure \ref{fig:Data3} is with a random replication value of 10\% when allowed duplicates = actual duplicates.
Figure \ref{fig:Data4} is the same values as before however with a replication value of 50\% to see how roughly this will effect the results.

We can see that having the replication value higher keeps data at a more consistent distance away from the data point rather than dealing with the fluctuations of the circluar movement of the agents.
From personal observations of the algorithm running it was observed that the data transfers became more volatile with the higher replication number.
Volatility meaning that data was replicated therefore making actual duplications to high then suiciding to get back down to the correct value, this would repeat often.
In a real world soloution this would not be ideal due to data transfers costing energy and possible data loss, this means that we need to design an algorthim that can take this into account more.

When comapring Figure \ref{fig:Data1}, Figure \ref{fig:Data2}, Figure \ref{fig:Data3} and Figure \ref{fig:Data4} we can impliy that the algorithm change doesn't affect the max distances like our desired outcomes want.
With this algorithm we do get the desired affect when dealing with non-correlated errors as shown in \ref{fig:Data5}.
In this graph we can see as the number of agents is decreasing the number of replications trys to fight that change, however some improvements might want to be made when a more thourgh investigation is done.
Correlated errors were not tested currently due to the failures in distance from the data point, we want a larger min max range of values before this is tested.



\section{Improved Heuristic}
\label{sec:Simple2}

To improve from the last design was to create a new heuristic that can take more into account and have scalable values, that can be modifyied to get diffrent behavoiur from the swarm network.
This was done by identifying diffrent factors that we want to play a role in the choose to replicate and the chose to commit suicide.
These were:

\begin{description}
\item[$\bullet$] Amount of agents in connection range that have a duplicated data compared to not having duplicated data
\item[$\bullet$] Distance to datas target area
\item[$\bullet$] Agents around average available public memory
\end{description}

The updated code can be seen in Algorithm \ref{Agent_Control_Loop2}, with this we can see that there are diffrent heurisitics for both suicide and replication.
With the above factors we made sure that they were bounded [0, 1] by doing ratios of the max value.
Then we had parameter values that sum to one as to show the percentage of what the parameter effects the heursitic, this can be seen in lines 12 and 15.
After these have been summed together the value is bounded between [0, 1] which we then set a threshold value for at what point we want the code benith to activate, e.g. Replication or Suicide.
Changing of these parameters creates diffrent charatersistics as an example can be shown with just replication and no suicide, Figure \ref{fig:Data6} and Figure \ref{fig:Data7}.

With this we can see that making the replication threshold higher decreses the likelhood of replication and gives a semi bound in a uniform density swarm and within non-uniform density swarm.
In figures shown you will see there is usally a black agent close to the red cricle (Data target area), this is because the agent that learned the data has it stored in private memory so isn't counted as changing colour to show it is a duplicated piece of data in public memory.
With both Figures we can see that suicide is definetly needed due to movement of agents as in Figure \ref{fig:Data7} and within Figure \ref{fig:Data6} we can see its needed due to all agents in an area around the point have the data.
This goes against what this storage policy is meant to provide, we need a way to vary duplicate density within that semi-bound around the data target area.

To this we add in the suicide option which only takes into account the first to features meantion in the bullet points above.
This will change the actions of the swarm to create a better policy as described in Section \ref{sec:Problem}.

As we can see in Figure \ref{fig:Data8} adding in the suicide ability and changing the threshold value creates diffrent duplication densitys within the replication bounds.
In simple terms it changes the desnity of duplications closer to the data target area if the density of agents is uniform in desnity.
When talking about non-uniform densitys it wil also take into account the desnity of agent duplications, however basically applies the same affect of having less duplicates where that is wanted, an example of this can be seen in Figure \ref{fig:Data9}.

With this current design it leads itself to diffrent observations based of parameter values.
The right values need to be picked for the algorithm to work effectivaly, for example sometimes if suicide threshold goes to low it leads to massive instability with repeating duplicates and suicides which is wasted bandwidth and energy.
This problem could be taken into account by also taking into account when the data was last replicated and allowing a sort of grace period within the heuristic to be able to allow natural movements to take those unstable agents apart.
The heurisitc and threshold values lends itself towards a learning algorithm for example a gentic algorithm to pick the best value for the certain task or wanted behavoiur.

As a prelimanry test run on an average of five runs, Figure \ref{fig:Data10}, we can see that we have managed to create an algorithm that is more stable to the periods of the swarms movement, in our case circles.
This was designed into the simulation to be able to test an algortihms abilitys to be able to handle fluctions in a repeating manner that can be visible.
We can also see that the range from maximum and minimum distances has now been increased which was something we wanted in for improvement from Algortim \ref{Agent_Control_Loop}.
However we can see that the mean value is roughly within the middle of the maximum and minimum value which leads me to believe that the algorithm isn't performing as expected.
We prefurably want the mean to tend towards being closer to the minimum rather than in the middle, this is to show the desnsity diffrence of duplicated data.
This will have to be investigated further as to whether it is the nature of the heuristic or whether it was the values of the parameters which were picked manually.

There is also an example of this algorithm running on a non-correlated errors in Figure \ref{fig:Data11}.
With this we can see roughly that the duplicates stay at about 40\% of the total number of agents even with non-correlated errors happening at a very extreme rate.
An observation within the simulations is some failures of agents can affect the total value suggnificantly until it gets into a stable state.
Due to the nature of the heuristic it is deterministic and likes to hang in an optimum as much as possible, therefore some loss of agents doesn't change much.
However sometimes an important agent is removed the duplicate layout changes quite quickly changing the layout across the swarm in a ripple like effect, until it gets back to an optimium (Stable state).




%%%%%%%%%%%%%%%%%%%%%


%%%% Analysis and Conclusion %%%%
\chapter{Conclusion}
\label{cha:conclusion}
%%%%%%%%%%%%%%%%%%%


\appendix
\chapter{Code apendix}

\begin{algorithm}
\caption{Agent's control loop}
\label{Agent_Control_Loop}
\begin{algorithmic}[1]
\Procedure{Step}{}
\State \text{move()}
\State
\If {item in private mem not in other agents public mem}
\State \text{Replicate item}
\State \Return true
\EndIf
\State
\State $item \gets \text{random public mem item}$
\State $allowed dupes \gets \textit{heuristic}(item)$
\State $current dupes \gets \text{(local) number of agents with item in public mem}$
\State
\If {allowed dupes > current dupes}
\State \text{Replicate item once}
\ElsIf { allowed dupes < current dupes}
\State \text{Suicide item using paxos}
\Else
\State \text{Randomly Replicate}
\EndIf
\State
\State \Return true
\EndProcedure
\State
\Procedure{Heuristic(Item)}{}
\State $dist  \gets \text{agent distance to items target point}$
\State $allowed dupes \gets \text{items max dupes} - (dist / \text{items step})$
\State
\If {allowed dupes <= 0}
\State \Return 0
\Else
\State \Return allowed dupes
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{Agent's control loop}
\label{Agent_Control_Loop2}
\begin{algorithmic}[1]
\Procedure{Step}{}
\State \text{move()}
\State
\If{Learned new private memory data}
\State \text{Replicate item to all agents in connection radius}
\State \Return True
\EndIf
\State
\State $dist \gets \text{euclidean distance to data}$
\State $dupes \gets \text{(local) duplicates on agents / number of agents}$
\State $pub space \gets \text{(local) average space available / max public memory}$
\State
\If{$(1-dupes) * b1 + ((\sqrt{8} - dist)/\sqrt{8}) * b2 + pub space * b3 > rep threshold$}
\State \text{Replicate item to all agents in connection radius}
\EndIf
\State
\If{$dupes * p1 + (dist/\sqrt{8})  * p2 > sui threshold$}
\State \text{Suicide data}
\EndIf
\State
\State \text{Iterate to next public memory data}
\State
\State \Return True
\EndProcedure
\end{algorithmic}
\end{algorithm}


\chapter{Results apendix}

\begin{figure}[htb]
\label{fig:Data1}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./PrelimData/SimpleSuicRep_m4_r0.5_c1_n50.png"}
\caption{Distance and number of duplicates on a run without a random replication factor}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data2}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./PrelimData/SimpleSuicideReplication_4d_4m_0.5r_50n.png"}
\caption{Distance and number of duplicates on a run without a random replication factor}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data3}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./PrelimData/SimpleSuicideReplication_n50_r0.5_c1_m4_repchance0.1_avg5.png"}
\caption{Distance and number of duplicates on average of 5 runs with a random replication factor=0.1}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data4}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./PrelimData/SimpleSuicideReplication_n50_r0.5_c1_m4_repchance0.5_avg5.png"}
\caption{Distance and number of duplicates on average of 5 runs with a random replication factor=0.5}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data5}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=10cm]{"./PrelimData/Non_correlated_errors_test1.png"}
\caption{Example of non-correlated errors on agents with a failure rate=0.003 per iteration}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data6}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./MiscImgs/Replication_No_Suicide_threshold_Together.png"}
\caption{Example of diffrent values of replication threshold on homogenus density swarm}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data7}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./MiscImgs/Replication_No_Suicide_threshold_0.8_c2_Non_uniform.png"}
\caption{Example of two datas on a non-uniform density agent network}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data8}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./MiscImgs/Rep_Sui_0.8_0.4-0.45_uniform_no_mo.png"}
\caption{Example of suicide threshold changes on data policy, on a uniform agent density}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data9}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./MiscImgs/Rep_Sui_no_uniform_no_mo.png"}
\caption{Example of suicide threshold changes on data policy, on a non-uniform density}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data10}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=8cm]{"./PrelimData/New_Replication_Scheme_No_Death_0.8r_0.45s.png"}
\caption{Example of Algorithm \ref{Agent_Control_Loop2}, with no failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:Data11}
\begin{center}
\centering
\includegraphics[width=\linewidth, height=10cm]{"./PrelimData/Non_correlated_errors_test2_0.8_0.45.png"}
\caption{Example of Algorithm \ref{Agent_Control_Loop2}, with failures at 0.003}
\end{center}
\end{figure}



\begin{thebibliography}{100}
\bibitem{Swarm robotics reviewed} 
J. C. Barca and Y. A. Sekercioglu, “Swarm robotics reviewed,” Robotica, vol. 31, no. 3, pp. 345–359, 2013.

\bibitem{Cognitive maps mine detection}
V. Kumar and F. Sahin, "Cognitive maps in swarm robots for the mine detection application," SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483), Washington, DC, 2003, pp. 3364-3369 vol.4, doi: 10.1109/ICSMC.2003.1244409.

\bibitem{Triggered Memory dynamic enviroments}
H. Wang, D. Wang and S. Yang, “Triggered Memory-Based Swarm Optimization in Dynamic Environments,” in Applications of Evolutionary Computing, M. Giacobini, Ed. Berlin, Germany: Springer-Verlag Berlin and Heidelberg GmbH \& Co. K, 2007, pp. 637–646.

\bibitem{Probabalitic automata foraging robots}
D. A. Lima and G. M. B. Oliveira, "A probabilistic cellular automata ant memory model for a swarm of foraging robots," 2016 14th International Conference on Control, Automation, Robotics and Vision (ICARCV), Phuket, 2016, pp. 1-6, doi: 10.1109/ICARCV.2016.7838615.

\bibitem{Swarm intellegiegence}
E. Bonabeau, M. Dorigo, and G. Theraulaz, Swarm Intelligence: From Natural to Artificial Systems. Cary, NC, USA: Oxford University Press, 1999.

\bibitem{Dynamic raid hybrid}
L. Xiang, Y. Xu, J. Lui, Q. Chang, Y. Pan, and R. Li, ‘A Hybrid Approach to Failed Disk Recovery Using RAID-6 Codes: Algorithms and Performance Evaluation’, Association for Computing Machinery, vol. 7, p. 11, 2011

\bibitem{CPU speed}
C. Mims, ‘Why CPUs Aren’t Getting Any Faster’, MIT Technology Review, 2010. [Online]. Available: https://www.technologyreview.com/2010/10/12/199966/why-cpus-arent-getting-any-faster/. [Accessed: 01-Dec-2020].

\bibitem{Raid parity}
U. Troppens, W. Müller‐Friedt, R. Wolafka, R. Erkens, and N. Haustein, ‘Appendix A: Proof of Calculation of the Parity Block of RAID 4 and 5’, in Storage Networks Explained: Basics and Application of Fibre Channel SAN, NAS, ISCSI, InfiniBand and FCoE, U. Troppens, Ed. Chichester: Wiley United Kingdom, 2009, pp. 535–536.

\bibitem{Avalability storage}
J. Liu and H. Shen, "A Low-Cost Multi-failure Resilient Replication Scheme for High Data Availability in Cloud Storage," 2016 IEEE 23rd International Conference on High Performance Computing (HiPC), Hyderabad, 2016, pp. 242-251, doi: 10.1109/HiPC.2016.036.

\bibitem{Distributed Storage}
N. Bonvin, T. G. Papaioannou, and K. Aberer, A Self-Organized, Fault-Tolerant and Scalable Replication Scheme for Cloud Storage. New York, NY, USA: Association of Computing Machinery, 2010.

\bibitem{LSA}
Legal Services Act. 2007.

\bibitem{Patent}
A. Prahlad, M. S. Muller, R. Kottomtharayil, S. Kavuri, P. Gokhale, and M. Vijayan, ‘Cloud gateway system for managing data storage to cloud storage sites’, 20100333116A1, 2010.

\bibitem{Scheme changes}
B. Czejdo, K. Messa, T. Morzy, M. Morzy, and J. Czejdo, ‘Data Warehouses with Dynamically Changing Schemas and Data Sources’, in Proceedings of the 3rd International Economic Congress, Opportunieties of Change, Sopot, Poland, 2003, p. 10.

\bibitem{Key-Value}
‘Key-Value Scores Explained’, HazelCast. [Online]. Available: https://hazelcast.com/glossary/key-value-store/. [Accessed: 02-Dec-2020].

\bibitem{Paxos}
L. Lamport, ‘The Part-Time Parliament’, in Concurrency: The Works of Leslie Lamport, New York, NY, USA: Association of Computing Machinery, 2019, pp. 277–317.

\bibitem{Quorum}
D. Agrawal and A. E. Abbadi. The tree quorum protocol: An efficient approach for managing replicated data. In VLDB’90: Proc. of the 16th International Conference on Very Large Data Bases, pages 243–254, Brisbane, Queensland,Australia, 1990.

\bibitem{RAID levels}
S. Lynn, ‘RAID Levels Explained’, PC Mag, 2014. [Online]. Available: https://uk.pcmag.com/storage/7917/raid-levels-explained. [Accessed: 06-Dec-2020].

\bibitem{HiveMind}
J. Hu et al., Eds., HiveMind: A Scalable and Serverless Coordination Control Platform for UAV Swarms. ArXiv, 2020.

\bibitem{blockchainandSwarm}
D. Calvaresi, A. Dubovitskaya, J. P. Calbimonte, K. Taveter, and M. Schumacher, Multi-Agent Systems and Blockchain: Results from a Systematic Literature Review. Cham, Switzerland: Springer International Publishing, 2018.

\bibitem{Space exploration}
L. A. Nguyen, T. L. Harman and C. Fairchild, "Swarmathon: A Swarm Robotics Experiment For Future Space Exploration," 2019 IEEE International Symposium on Measurement and Control in Robotics (ISMCR), Houston, TX, USA, 2019, pp. B1-3-1-B1-3-4, doi: 10.1109/ISMCR47492.2019.8955661.

\bibitem{UAV}
M. Y. Arafat and S. Moh, "Localization and Clustering Based on Swarm Intelligence in UAV Networks for Emergency Communications," in IEEE Internet of Things Journal, vol. 6, no. 5, pp. 8958-8976, Oct. 2019, doi: 10.1109/JIOT.2019.2925567.

\bibitem{Ant communication}
D. Jackson and F. Ratnieks, ‘Communication in ants,’Current Biology,vol. 16, pp. 570–574, 2006.

\bibitem{Boids}
C. W. Reynolds, Flocks, Herds, and Schools: A Distributed Behavioral Model. ACM, 1987.

\end{thebibliography}



\end{document}


%%%%%%%%%%%%%%% Example
%\begin{figure}[htb]
%\begin{center}
%\includegraphics[height=3cm]{"./UOY-Logo-Stacked-shield-Black"}
%\end{center}
%\caption{A figure containing UoY logo and its caption.}
%\end{figure}


%\begin{table}[htb]
%\caption{ A table with its caption.}
%\begin{center}
%\begin{tabular}{|p{0.3\textwidth}|p{0.6\textwidth}|}
%\hline
%column A & column B \\\hline
%row 1 &
%Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque quis quam at nisi iaculis aliquet vel et quam. \\\hline
%row 2 &
%Aliquam erat volutpat. Nam at velit a risus faucibus aliquet. Aenean egestas vehicula mi, quis rhoncus sem facilisis in. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed lobortis %lacus quis mauris rutrum auctor. \\\hline
%\end{tabular}
%\end{center}
%\end{table}
