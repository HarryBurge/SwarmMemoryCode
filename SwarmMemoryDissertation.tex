\documentclass{UoYCSproject}
\author{Harry Burge}
\title{Swarm Memory}
\date{2021-April}
\supervisor{Simon O'Keefe}
\MEng

\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\dedication{}

\acknowledgements{
 // TODO
}

% More definitions & declarations in example.ldf

\begin{document}
\pagenumbering{roman}
\maketitle
\listoffigures

\bibliographystyle{ieeetr}
%\renewcommand*{\lstlistlistingname}{List of Listings}
%\lstlistoflistings

%%%% Executive Summary %%%%
\begin{summary}
This report proposes and tests solutions for directional memory storage policies within a swarm environment. The proposed solutions are to provide redundancy for correlated and non-correlated failures, without pure duplication of data throughout the swarm. Directionality of the policies is defined as a higher density of duplications nearer to the point that information is needed.

A simulated homogeneous swarm is used to provide results on two different designs of policies. Each swarm agent has the ability to perform four actions, Replication, Suicide, Migration or Nothing. These actions can be performed on data stored in their memory to gain redundancy from both types of failures. Replication duplicates data to other agents. Suicde deletes the data. Migration passes the data onto another agent and nothing is as the name suggests.

A design is the way we control an agent's actions in order to get emergent characteristics. This emergent behaviour will be reviewed using five different global factors. Amount of duplications per data point, distance between a duplication and its desired location, instability of the system, agents memory usage and a visualisation of duplications ratio over the 2D plane. Performance will be based on levels of duplication with a roughly even distribution per data point, having a large range of distances with a mean close to the minimum and for instability to be of lowest magnitude. These factors are tested on both circular motion and semi-static motion in order to see how behaviour changes over different swarm environments e.g. lots of volatility in connections or stable connections. Within each movement style correlated and non-correlated failures are tested to see the effectiveness and characteristics of the proposed method.

The intial version of the first design style used a weighted sum with a threshold for both suicide and replication. The input factors are; duplications ratio in the locality of the data selected, distance to the desired data point of selected data and average spare memory left on agents in the locality. This version performed adequately in most factors, however, stability left room for improvement, uneven distribution of memory load and poor handling of a volatile connectioned swarm.

The second version of the first design style carried on from the previous by changing the static thresholds to be dynamic, in order to counteract the stability problem of the previous version. To measure instability on a local scale, as each agent received a duplication request, would increase an instability variable, this would be reduced over time. Output of sigmoid functions were added to the weighted sum, with inputs being time from last suicide for the sucide threashold and instability for the replication threashold. The version achieved its target by significantly reducing the magnitude of instability without changing behaviour of the previous version. The nature of the instability changes within a circular motion swarm to being roughly constant instability compared to the periodic nature of the static heuristic. However, there was still the issue of duplication load over the swarm.

The third version of the first design style implemented migration. Migrations threshold is controlled by, if we would statically replicate this item and the agent in the locality with the most available space is higher than the current agents available space. As expected this increased the instability due to more movement of data. The spread of workload was significantly better in semi-static swarms compared to the circular counter parts. Therefore leading to different use cases for both the second and third versions.

%The third version should be used in situations where swarms are relatively stable or instability is less of an issue due to stuff like power consumption. The second version should be used in situations where either the swarm is naturally highly unstable, size of memory is heavily restricted or power consumption is a major factor. The first version is overall less effective than the second or third, so should not be used.

Having reviewed the first design style even though performance as defined was good, it still lacked effectiveness when compared to a theoretical best solution. This is because the algorithm doesn’t take into account many edge cases or complex behavioural changes based on multiple thresholds. This led to using the computational power of neural networks in order to solve for these complex behavioral characteristics. A genetic algorithm was used to train the neural network, using a global fitness function post simulation run with each agent using the same network. Unfortunately, the learning rate was very slow due to selected hyperparameters and poor judgement on fitness function evaluation being only one simulation run. Therefore, it led to a non-testable version due to the extremely poor performance.

%Overall the project was a partial success, with good results coming from the handcrafted designs but a failure from the learning results from the multi-agent interaction design.

The field of swarms are riddled with ethical and moral issues. Specifically, swarms have a high potential to be abused in surveillance, breaching people's privacy. Within the military domain, is it ethical to have systems having choice over human life, but also are so resilient the opponent doesn’t have any chance? Socially, is it acceptable to have self piloting drones flying around delivering packages at all times of day and night? Environmentally, a swarm solution will nearly always use more energy and cost more CO2 to produce in any significant size, when compared to a single robot solution. In terms of security, allowing multiple more access points to a network also increases risk, especially if each agent/node has locally stored accessible data.
%Even with the ability to abuse swarms and the threats that they impose, the author believes that the good that they can provide to society significantly outweighs the negatives, especially taking into account future technologies and space exploration.

\end{summary}


%%%%%%%%%%%%%%%%%


%%%% Itntroduction %%%%
\chapter{Introductury Material}
\label{cha:Introductury Material}

%%%% Problem Definition %%%%
\section{The Problem}
\label{sec:Problem}

The problem this report tries to solve is the creation of a directional memory storage policy for agents in a swarm, without complete duplication.
This can be split into two separate sub-problems.
The first is the handling of data duplications throughout the swarm to control for failure of agents, and provide a mechanism for recovery.

\begin{figure}[htb]
\label{fig:popdensity}
\begin{center}
\centering
\includegraphics[width=\linewidth]{"./ExplanationImgs/Memory_Pop_Density.png"}
\caption{Data duplication density based on distance to a datas desired location}
\end{center}
\end{figure}

The second is to apply directional characteristics to the above method.
A visualization can be seen in Figure \ref{fig:popdensity}, where density of duplication decreases as distance from a desired location is increased.
Each piece of data should have its own desired location.

A real life example of this type of problem arises in mine field operation \cite{Cognitive maps mine detection}.
Agents need to map out potential mines and record their location.
Once an agent locates a mine it wants to spread the mine’s location.
However, memory restrictions in agents only permits the knowledge of a minimal amount of mines.
Agents closer to the mine should be prioritized in knowing that mine’s location.
Agents further away from the mine do not need to know about its location, because they will need knowledge of other closer mines.

Complexity is increased taking into account a practical implementation of this problem.
Firstly the policy has to withstand fluctuations of a swarm, which is a hard task in and of itself.
But secondly, handle correlated (Mine detonation) and non-correlated (Individual power loss) failures, with minimal loss of data.



%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:Introduction}

The objective of this report is to solve the problem defined in Section \ref{sec:Problem}, with an effective and reliable policy which can withstand high locality and dynamic behaviours of a swarm.
Analysis will then be performed on generated policies as to gauge their real world capabilities and effectiveness.

Two design styles will be undertaken, with an emphasis on the first.
This design will be handcrafted and will give an indication of how effective a policy of this type can be.
The second will use a multi-agent interaction approach using a neural network, which will be compared against the handcrafted policy.
Policies will be rated based on a few key characteristics; ability to handle both types of failures, over or under saturation of duplication and stability of the policy.

To complete this objective, we will programmatically break down the problem described in Section \ref{sec:Problem} into solvable tasks.
The report will be structured as follows, firstly bringing the reader up to date with relevant literature and explaining key concepts required for a complete understanding of how the proposed solutions have been derived.
This will be undertaken in sections, Section \ref{sec:Cloud} of which goes into detail about current cloud based storage technologies and Section \ref{sec:Robotics} which delves into more of the background behind swarms, specifically relating to the problem and possible solutions.
We’ll go through the methodology of the proposed solutions’ designs, how it is supposed to act and react in different scenarios, and the reasons for why.
Leading to analysis of how effective the proposed policies have kept to standards derived in the methodology section, and whether they effectively solve the problem defined in Section \ref{sec:Problem}.


\section{Background and Motivation}
\label{sec:Motivation}

Swarms are an increasingly important area of research for society, as the world moves towards a distributed technology future.
The research of swarms within a technology setting can be broadly divided into two partitions, these are intelligence and mechanics.

Swarm intelligence can be viewed as the research into highly distributed problem solving\cite{Cognitive maps mine detection, Swarm intellegiegence}.
This is ever more becoming relevant as computer systems start to level out in sequential performance \cite{CPU speed} and parallelism is embraced, satisfying the demand of the age of big data \cite{Avalability storage}.

Swarm mechanics leans towards the robotics side and can be seen as the study of practical implementation of a swarm, whether that be movement or communication.
This is on the rise in industry, as society's pace increases and manual labor is automated. Whether its drone delivery to inpatient customers or mapping areas in dangerous environments \cite{Swarm robotics reviewed}.

These areas often are highly integrated and are rarely seen in their pure form.
An example of a pure form of swarm intelligence can be seen in \cite{Swarm intellegiegence} with network routing protocols.
This project focuses predominantly on swarm intelligence to deal with a practical problem.

Most research on memory within a swarm has followed the route of optimization on distributed problem-solving algorithms, compared to practical applications of storage of abstract ideas as a collective.
As one of the key reasons for using a swarm is redundancy, which is often assumed and boasted about, rather than proven, specifically within the memory domain.

The relative lack of research into collective memory, appears to be a glaring hole in the foundations of a complex and interchangeable subject.
The need for more research into collective memory can be seen in examples, such as how invaluable it would be in the mapping of dangerous areas \cite{Cognitive maps mine detection}.
By being able to handle the loss of agents combined with the redundancy of sufficient memory policy, provides a much wider scope for swarm usage.

An explanation for why swarm based memory management solutions are an under developed area of study is the existence of cloud-based storage research.
The argument for these two subjects being partially-separated is the nature of a swarm's locality and ever-changing network style, compared to a typical server network.


Most elements of cloud storage policies at a high level of abstraction could work effectively within a swarm based environment.
However as mentioned above, key adaptations would need to be created for an effective policy.
A prime example is “SKUTE” from \cite{Distributed Storage}.
“SKUTE” will be the main inspiration for this project's solution, to storage within effectively a highly dynamic network.

Currently the main issues for swarms are within surveillance \cite{UAV, HiveMind}, delivery or the military \cite{Swarm robotics reviewed}.
However, to see the full scope of what man-made swarms could do, we look to the future.
Whether it be space exploration \cite{Space exploration}, nano-robots in medicine or in the parallel/distributed software domain \cite{blockchainandSwarm}.

Swarm robotics is limited by the technology of its time.
The use of research is limited and far between in our day and age.
Research is conducted in mind for the future when technology can support and utilize the fullest potential swarms can offer.


%%%%%%%%%%%%%%%%%%





%%%% Litreture Review %%%%
\chapter{Literature Review}
\label{cha:Litreture Review}

\section{Cloud/Backup storage policys/schemes}
\label{sec:Cloud}

Like most things in computer science, cloud storage started off relatively simple.
As the years have progressed so has the demand for the cloud, varying from everyday people storing files to large businesses storing harvested data.
An increase to complexity of solutions came from the Legal Services Act. 2007 \cite{LSA}.
This enforced cloud storage suppliers, to provide reliable, fast and redundant data storage and collection for all users.
In this section we focus on cloud-based storage policies and some background terminology required for this report.

Firstly the reader needs to understand the difference between correlated and non-correlated failures.
A non-correlated failure is when a device fails independently, with no relation to other failures within the system as a whole.
For example, a server node can shut down from a software failure, therefore connection is lost, typically this is completely independent of other servers in the rack.
The opposite, correlated failure, is when multiple devices fail with a relational link.
A typical example is on-mass restarts from a power surge in a data-center.
The power surge event is the relational link that binds the events together.
Correlation doesn't require close geographical location, however, when mentioned later on in the report, it should be regarded as such.

There are multiple defensive strategies which can be employed to control for both failure types.
Focusing on strategies that are reactionary rather than preventative.
For local redundancy, typically RAID is used to ensure safety in a storage failure.
A replication policy \cite{Avalability storage} is used for internode redundancy.
By working in tandem achieves extreme redundancy against both types of failures.

A replication policy selects a piece of data and decides whether it needs to be replicated, and if so where it should be stored/located.
This duplication of data onto another storage device means that if one fails, we still have a full replica to access.
A simplistic approach would be a random replication policy, where data is randomly chosen to be duplicated.
This is an acceptable policy for handling failures, however, without tracking of global duplications it potentially can lead to over used storage.
It also doesn’t take into account the popularity of certain items.
An algorithm like random replication, is substantial for long-term storage where popularity of data and distance to users are averagely the same for all data items.

Cloud based storage transitioned from a semi-local backup system to a worldwide daily driver.
Random replication couldn’t withstand the variability of how users interact with files nowadays.
For example, a video is hosted in one country and replicated within said country then international viewers might have delays to their streaming.
Alternatively, trying to compensate we host in multiple countries, those other countries might have reduced views.
This means storage is wasted, of which we could use for other more popular videos.
This leaves us attempting to maximise for both situations, and a new replication policy is required.

These new algorithms extracted from papers handling "Distributed key-value store" \cite{Key-Value}, where key-value pairs are on multiple devices on a network and duplication only leads to more fault tolerance of the data stored.
The first approach uses a privileged level of control where the master uses global knowledge to make decisions about whether and how to duplicate items \cite{Avalability storage, Patent}.
The same principles can be seen within schema changes \cite{Scheme changes}.
Due to the nature of a privileged user, control of the policy is deterministic and easy to control.
This leads to higher guarantees for failures unless on the master node, however this can be handled dynamically by assigning another master. 
Touched upon in Section \ref{sec:Robotics}.
Availability and popularity are handled by the policy heuristic controlled by the master node.

Having this master approach doesn’t work effectively for a swarm.
This is because the change from a server network to a swarm is quite drastic.
Servers running over a network generally have complete connectivity e.g. Global scope.
Servers also have a constant power supply compared to the average swarm agent.
When restricting the masters scope we have to rely on messages bouncing from agent to agent.
This will first of all reduce processing capability, power loss will be most significant in agents closest to the master, possibly leading to a cut off from command \cite{Swarm robotics reviewed}.
It also doesn’t fit into the ideology of a swarm, this will be talked about in Section \ref{sec:Robotics}.

The second approach doesn’t rely on a privileged member and can be adapted for locality.
Each node (In the case described below its each key-value pair) has its own controller for when and how to replicate, following a distributed control structure.
Following the approach used with “SKUTE” as proposed in \cite{Distributed Storage}, it can make four decisions per data item.
These decisions are; Migration, Suicide, Replication, and Nothing.

Migration transfers itself from the origin to a lower cost or more redundant server.
Suicide is the removal of itself, this will usually be due to excess duplications.
Replication is when it decides it needs to be duplicated onto another server.
Nothing is as the name indicates.

The highly distributed nature lends itself to failures of parallelism.
For example, two data points might want to suicide and will do so.
Whereas if we ran them sequentially it could be possible that if one suicided the other might not.
If only two agents remained with contained duplicated data then the policy could fail to retain data.
This is where a consensus algorithm comes into play.
Paxos \cite{Paxos} is an example of how both nodes couldn’t suicide at the same time.
This essentially creates a part-time leader agent to control a suicide action.

Within the server storage domain an approach like “SKUTE” is less commonly used because it adds complexity which is unnecessary within a global scope and consistently powered network.
Most data warehouses would prefer to have one server running as a controller and other servers running at full capacity compared to all servers at a slightly lower capacity due to extra self computation.
However this approach allows for greater hypothetical redundancy because of having no single point of control.

Moving towards local redundancy and optimisation is the stagnated study of RAID.
This is where we change orderings of multiple storage discs to gain redundancy and/or performance increases.
This grouping of disks is called a RAID array and can be structured in a multitude of ways.
Common structures are labelled as RAID levels and give different attributes based on what functionality you are pursuing \cite{RAID levels}.

One of the key components of multiple RAID levels is the use of parities \cite{Raid parity}.
This is where a function (Simplistically an XOR) is done on two or more sets of data to create one or more parities.
This function has a property enabling a tolerant amount of disks to be lost, and after the event be used to reconstruct lost data.
In the case of data A, data B and A XOR B, if data B is lost then can be reconstructed using data A and A XOR B.
With different levels and functions more than one disk can fail and still retain data, however if disc failures increased over the specified limit then reconstruction cannot occur.
RAID is predominantly used internally within a storage node to provide redundancy against disk failures and increase speed of writes that are typically on hard disks.

The methodology is, so long as the nodes individually are redundant enough and there is control on a higher level with our replication schemes, then it is sufficiently redundant.



\section{Swarm robotics}
\label{sec:Robotics}

Explained broadly in the Section \ref{sec:Introduction}, the study of swarms are split into two subsections, mechanics and intelligence.

The concept of swarm intelligence is creating a solver to a problem using a distributed algorithm that can rely on natural parallelism, doesn't rely on global knowledge and is adaptable on the fly, in comparison to their counterparts.
From papers read by the author, predominantly the topics investigated are testing distributed solvers and comparing them against already researched global scope solutions.
Examples of this within the TSP domain is a genetic algorithm versus AS-TSP \cite{Swarm intellegiegence}.
These algorithms also excel in the networking domain, because of the high parallelism and need for adaptability \cite{Swarm intellegiegence}.

The other subsection can be broadly known as swarm mechanics.
Swarm mechanics focuses on problems that are less abstract and are usually in the domain of physical implementation \cite{Cognitive maps mine detection, Probabalitic automata foraging robots}.
Swarm robotics is a subset of swarm mechanics, and is justified thusly; within this domain we focus on the emergent behaviour of a swarm compared to the solution it might give.
The second is that swarm robotics doesn’t encompass the study of swarm behaviour in nature \cite{Swarm intellegiegence, Ant communication}.

Delving deeper into swarm mechanics there is three different methodologies, heterogeneous, homogeneous and hybrid \cite{Swarm robotics reviewed}.
These can be adopted in multiple ways, however, we focus upon the adoption of these methodologies in decision making and physical attributes of agents.

\begin{figure}[htb]
\begin{center}
\label{fig:anthero}
\includegraphics[height=4cm]{"./ExplanationImgs/AntHetro.png"}
\end{center}
\caption{Example of a hetrogenus ant colony}
\end{figure}

A heterogeneous swarm is defined by differences between agents of the same swarm, as in Figure \ref{fig:anthero}, whether physically or mentally \cite{Swarm robotics reviewed, Swarm intellegiegence}.
These occur commonly in nature and are a less researched sub-field of swarms \cite{Swarm intellegiegence}.
For real-world solutions, heterogeneous swarms can be of great use, allowing certain agents to pick up slack of the swarm, or complete tasks that other swarm members cannot complete.
A good example described in \cite{Swarm robotics reviewed} with a mother ship being a navy boat and a swarm of quadcopters.
The boat picks up the slack of the swarm by transporting them longer distances than the swarm could independently complete, whilst also carrying complex hardware.

The argument against heterogeneous swarms is a tendency to over rely on the differences of agents.
Running with the example from \cite{Swarm robotics reviewed}, the agents rely on the naval boat to be able travel longer distances and for a recharge point.
Without the boat the swarm fails at completing its prolonged objective.
The decision to use a heterogeneous swarm in this case is valid because if the naval ship is lost, then a catastrophic incident has occurred and the swarm is probably not the highest priority.

Physical differences in agents breeds efficiency.
However, this can only hold true if the vulnerability of a substantial loss of a key class is mitigated.
Common rules for mitigation are found in nature's swarms.
They are; jobs need to be interchangeable between all types of agents however some agents are more efficient at that job \cite{Ant communication} or specific jobs are non-essential to the colony's survival.
These swarms are under researched because human implementations currently lack the adaptability of biology, so this vulnerability has to be taken into account.
Some ant species, like Leaf-Cutter Ants, even have subcategories within a category of type.
Leaf-Cutters have workers specialising in certain tasks like fungus farming.
The best example of showing the interchangeability of these roles is when major ants do worker jobs when there is a significant loss of workers \cite{Swarm intellegiegence}.

Homogeneous swarms are defined by each agent being the same.
This is found less often in nature, except for the microbial level.
Biology's natural adaptability compared to robotics means that semi-heterogeneous swarms are exploited better in nature \cite{Swarm robotics reviewed, Swarm intellegiegence}.
Therefore we maximise for the flaws of our current technology.
Technically homogenous swarms provide the best platform, but that is getting into speculative futuristic technologies of self replication, advanced intelligence and nano robotics.

Homogeneous swarms benefit from maximum redundancy, if any agent fails there remains an entire swarm's worth of agents to take its place.
With the benefit of redundancy we acquire some possible losses in efficiency which could have been exploited with task specific hardware.
Either the agent is too simplistic, losing efficiency in their tasks, or are too complex, to the point that all agents have the capability for every specialism but may never need them.
There is a thin line between the two, either we lose practical power of the swarm or we have to invest more into the swarm than is actually needed.

Within the practical implementation of swarms things become disorganised.
Usually there is no clear cut framework of which a practical swarm uses.
This is where engineering and research have a disconnect, and hybrid swarms come into their own.

A hybrid approach tries to exploit the benefits of both heterogeneous and homogeneous designs without the downsides.
Using a farmer and miner agent example, a hybrid approach to physicality would be that each agent has exactly the same body and could wield either a pickaxe or a hoe. The key point is that a miner could become a farmer if required.
The reader might wonder why physical hybrid approaches aren’t regarded as the best approach for all swarms.
Bringing this theoretical solution into the real world can cause massive complexity.
How can we guarantee job type distribution?
What about the complexity of changing between job type hardware?
These are all questions that need to be explored, by the designer/creator.
Normally it is easier to go for the simpler solution and deal with the possible loss of either efficiency or adaptability.

Homogeneous control is where each agent controls its own decisions based on its locality, sometimes labelled distributed intelligence.
This creates an emergent/structured global behaviour of the swarm even though each agent is acting of its own fruition.
A simple example of this is \cite{Boids}.

Heterogeneous control is where specified agents control other agents' decision making.
This can be handled in different ways, two prominent ways are hivemind control \cite{HiveMind} and royalty/hierarchical control.
Hivemind is where one agent controls the entire swarm's decision making e.g. the master controller will give abstract ideas as parameters and the agents will execute them with their own decision making.
A hierarchical approach follows the same style as hive mind, however, it deals with scalability better.
Enabling a power structure of certain agents being sub leaders of leaders.
Both control structures leave themselves vulnerable in its physical implementation due to bad actors and power loss distributions over the swarm.

Hybrid control of a swarm is a heterogeneous policy that is adaptable to changes of leaders and is usually designed for a physically homogeneous/hybrid swarm.
The choice of leader(s) is done through a consensus algorithm \cite{Paxos} rather than based on any form of physical or mental difference.
This allows homogenous style agents to act in heterogeneous fashion.
This creates more deterministic behaviours compared to emergent behaviors of homogeneous control, it can also help power loss distribution by re-electing leaders in different locations to help distribute where messages are relayed.

%%%% Approach motiviation and justification %%%%
\section{Approach and Justification}
\label{sec:Inital Soloution Ideas}

An initial solution was to use an adaptive version of RAID parities. However, a more effective concept solution became apparent after conducting further research into cloud based storage.

Within the adaptive RAID design, if a subject agent has two agents within its locality with different data, an XOR parity of both data points would be recorded alongside a record of originating agents. If one of those agents left the subject locality then the parity would be used to reconstruct lost data. This approach was disregarded because of the following factors:

\begin{itemize}
\itemsep-1em
\item[$\bullet$] Implementation of directionality would be difficult and inconsistent
\item[$\bullet$] If the two agents die/leave the locality at the same time then the parity cannot be restored
\item[$\bullet$] The algorithm relies on a swarm breaking connections often to spread data
\item[$\bullet$] There is no duplication reduction, over time the data point would spread to all agents
\end{itemize}

These drawbacks highlighted the need for a new approach, cloud based-storage policies. The proposed solution takes heavy inspiration from “SKUTE” \cite{Distributed Storage}. The design of a replication policy lends itself to heuristic based control, and enables implementation of duplication density and direction to the spread of data.

A distributed/homogeneous style of control is used, partially because there is an average power loss over the swarm compared to a leader based control, but mainly because of the methodology of a homogeneous swarm. A hybrid approach, if not accounting for power loss, would almost certainly be better in every single way, due to its global view. A hybrid implementation would be very simple and deterministic compared to its homogeneous counterpart. Both methods could not guarantee data loss would not occur, however, a hybrid approach would be better equipped to handle correlated failures.

With an extensive list of drawbacks to using a homogeneous control over a hybrid control scheme, it would be deemed inappropriate to use homogeneous control. This disgruntlement is valid only when talking about swarms that are partially static in nature. When the swarm is highly volatile, in terms of movement, more time could be spent assigning a leader rather than completing the actual task. Scaling of a hybrid system is harder because of the partitioning of agents to leaders. This justifies the author's decision to focus on distributed homogeneous replication policies.
%%%%%%%%%%%%%%%%




%%%% Methodology/Design Chapter %%%%
\chapter{Design}
\label{cha:Design}

\section{Experiments}
\label{sec:expriments}

To understand and evaluate the proposed solutions it’s necessary to see how they react to different scenarios.
The scenarios are designed to test functionality of the proposed solution.
These are:

\begin{itemize}
\itemsep-1em
\item[$\bullet$] Semi-Static moving swarm with non-correlated failures, Figure \ref{fig:static_movement_non}
\item[$\bullet$] Semi-Static moving swarm with a correlated failure, Figure \ref{fig:static_movement_con}
\item[$\bullet$] Circular moving swarm with non-correlated failures, Figure \ref{fig:circle_movement_non}
\item[$\bullet$] Circular moving swarm with a correlated failure, Figure \ref{fig:circle_movement_con}
\item[$\bullet$] Changing of replication and suicide thresholds, Figure \ref{fig:Threshold_Changes}
\end{itemize}

Semi-static movement, as described in Algorithm \ref{Agent_Control_Loop2} is used to test the solution on mostly stable networks, allowing us to see the solution's inherent stability.
In the opposite case we have circular movement which adds physical instability.
This allows comparison of stability with internal and external factors.
Correlated and non-correlated failures should be self explanatory, as being key to the problem defined in Section \ref{sec:Problem}.

The proposed solutions will be simulated and critiqued based on five factors.
Number of duplications, this allows us to see whether the policy over or under saturates duplications and how they are affected by loss of agents.
Distance from desired point, shows acceptable ranges for correlated failures, therefore, the larger the range the better it is.
Instability, as most swarms will be battery powered, we need to reduce the amount of communications between agents, reduce communication power consumption, to have a practical solution.
Storage load across the swarm, this allows us to see how effective our policy is at distributing load over the agents so as to not oversaturate an agent causing potential exclusion of agents.


\section{Static Heursitic}
\label{sec:Simple2}

This solution takes heavy inspiration from Paper \cite{Distributed Storage}.
We utilize the methodology of each agent controlling its own data and distribution of data, through actions of Replication, Suicide and Nothing.
Migration is not applied, so we piggyback on the natural movements of the swarm to extend duplications range.

Thresholded heuristics decide whether to undertake either action, based on these factors:

\begin{itemize}
\itemsep-1em
\item[$\bullet$] Ratio of agents in locality that do and do not have duplicates
\item[$\bullet$] Distance of the data’s point
\item[$\bullet$] Agents average spare memory in locality
\end{itemize}

The values collected undergo a weighted sum and are compared against thresholds.
A pseudo code version of this can be seen in Algorithm \ref{Agent_Control_Loop2} inserted into Algorithm \ref{Agent_Control_Loop1}.
Every step an agent will check whether it has learnt any new private data, if so, then duplicate that data to all agents in the locality.
If no duplications happen, it’s because no suitable agents are in the locality, the data will have this action performed on the next iteration until it succeeds.
This quick replication provides redundancy to non-correlated failures, as fast as possible.
Most of the time this action will be redundant, until exceptions happen, calling this into play.

For each iteration we focus on one public data point in memory, this is a basic iteration through memory.
A further improvement could be dynamically choosing which data point to service, discussed further in Section \ref{sec:further}.
The current implementation is unable to perform effectively for large data amounts e.g. scales badly.


An agent broadcasts packets to agents in their locality to gain information required.
Agents receiving packets respond with relevant information, e.g. do they have a duplicate of the data point, amount of spare memory, etc.
Once collated by the originating agent, it works out the specified values, shown in equations below.
There are improvements that can be made to the handling of broadcasting/replying and will be explained further in the Section \ref{sec:further}.

After collating the values we scale them from 0 to 1, and rearrange for them to increase in size when we are more likely to want an action to be taken.
For example, a higher density of duplications leads an agent to be less likely to replicate $1-dupes\_ratio$.

\begin{figure}[htb]
\label{fig:changing}
\begin{center}
\centering
\includegraphics[height=5cm]{"./ExplanationImgs/planned_changes.png"}
\caption{Example of changing of replication and suicide threshold on a uniform agent density}
\end{center}
\end{figure}

Changing weightings and thresholds applies significant behavioural changes within the policy.
Increasing replication threshold means that duplications will spread out less distance, avoiding higher duplication density areas and reducing spread when agents are already saturated with data.
The higher the suicide factor indicates there is less of a duplication density diffrence across the network.

To enable easier understanding of the heuristics behaviour when changing threshold values we can refer to Figure \ref{fig:changing}.
This demonstrates how the heuristic changes behaviour with varying threshold values, influencing the spread of duplicated data from a data point in a uniformly spaced swarm.
The smaller red dots represent agents that have a duplicate with data points of the large red circle.
Replication threshold increasing magnitude can be seen by the changing in distance, e.g. indicated by the blue circle.
And suicide threashold when increasing changes the duplication density spread, e.g. from left to right, right being larger in magnitude.

\begin{equation}
\label{eq:static_vals2}
\textbf{X}_{rep} = \begin{bmatrix}1-r & \frac{\sqrt{8}-d}{\sqrt{8}} & s \end{bmatrix}
\textbf{X}_{sui} = \begin{bmatrix} r & \frac{d}{\sqrt{8}}\end{bmatrix}
\end{equation}

\begin{equation}
\label{eq:static_vals1}
\textbf{W}_{rep} = \begin{bmatrix}0.45 & 0.45 & 0.1\end{bmatrix}
\textbf{W}_{sui} = \begin{bmatrix}0.3 & 0.7 \end{bmatrix}
\end{equation}

We then workout $h_{rep}$ and $h_{sui}$ using multiplication as below:

\begin{equation}
\label{eq:10}
h = \textbf{W} \textbf{X} ^{T}
\end{equation}

Where r is duplication ratio, d is distance to the datas target point, s is average spare storage in agents in the locality.
The factors weights can be adjusted to fit different behaviour styles.
For example you could favour distance from data point over current duplication density.
Having the weighted sum enables the heuristic to be optimised by fitting techniques such as  genetic algorithms.
This would have to be tailored to individual applications because of no dynamic nature to threshold setting.
In tests we used values \ref{eq:static_vals1}, without any significance but purely from tinkering to get good results.

Initially “suicide data” in Line 16 of Algorithm \ref{Agent_Control_Loop2}, was done using Paxos \cite{Paxos}.
This ensured that a data point could not end up going extinct from suicide, and would only occur with external factors (Failures).
However from preliminary tests this didn’t make a significant difference in our scenario, but should be added into any practical applications of this algorithm for greater guaranteed redundancy.


\section{Dynamic Heuristic}
\label{sec:Simple3}

To control instability of the static heuristic, as described in Section \ref{sec:Simple2a}, we need to enforce a behaviour so when instability increases, factors contributing to instability are reduced.
Rather than polling agents in the locality for wider stability information increasing network congestion, computation time and power consumption.
We instead use locally tracked information within the agent in order to gain an understanding of local/global instability.

Firstly, to control instability of the swarm, it wants to reduce the chance of suicides happening after one has occured for a period of time.
This in and of itself will not solve instability, however, slows its affects down.
The previous heuristic attempts to seek a global optimum where it becomes static.
In an unstable state the optimum keeps changing at the fringe.
Therefore restricting our suicides enables the possibility of replicating to a key agent outside the usual bubble which could lead to a static optimum.
However, this only hopefully solves instability issues at the fringe and not inside the swarm.
This is why we restrict the chances of replications based on local instability.
Local instability is tracked per agent with a variable that as a request comes in to duplicate data from another agent, a constant is added to the variable, after every iteration we lose some of the variable's magnitude.
This gives the agent a partial picture as to how the locality is behaving.
The combination of both feedback mechanisms should decrease instability and smoothen the effects over time.

To achieve these behaviours we modify the current heuristic using sigmoid functions, based on the inputs described abstractly above, which are used to modulate the thresholds to give them a dynamic coping mechanism for instability.

For replication:
\begin{equation}
\label{eq:1}
\lambda_{rep} = \big( \frac{1}{1+ e^{- \frac{ \theta - \alpha_{rep} }{ \beta_{rep} } } } \big)
\end{equation}

\begin{equation}
\label{eq:100}
\textbf{W}_{rep} = \begin{bmatrix}0.45 & 0.45 & 0.1 & -0.6 \end{bmatrix}
\textbf{X}_{rep} = \begin{bmatrix} 1-r & \frac{\sqrt{8}-d}{\sqrt{8}} & s & \lambda_{rep} \end{bmatrix}
\end{equation}

For suicide:

\begin{equation}
\label{eq:2}
\lambda_{sui} = - \big( \frac{1}{1+ e^{- \frac{\psi - \alpha_{sui} }{ \beta_{sui} } } } \big) + 1
\end{equation}

\begin{equation}
\label{eq:101}
\textbf{W}_{sui} = \begin{bmatrix}0.3 & 0.7 & -0.6 \end{bmatrix}
\textbf{X}_{sui} = \begin{bmatrix} r & \frac{d}{\sqrt{8}} & \lambda_{sui} \end{bmatrix}
\end{equation}

$\theta$ in Equation \ref{eq:1} is iterations since last suicide, once a suicide occurs on the agent $\theta=0$.
$\psi$ in Equation \ref{eq:2} is a value based on how many agents asked the current agent to store a bit of data, this naturally increases as instability is increased.
$\psi$ is reduced every iteration until 0.

Sigmoid functions were used because we can control when the heuristic should be unimpeded or impeded, with a grey area in between so if data needs to be duplicated quickly it can still override the blockade.
$\alpha$ and $\beta$ can be changed on both heuristics to give different behaviours.
A pseudo code example can be seen in Algorithm \ref{Agent_Control_Loop3}.


\section{Dynamic Heuristic with Migration}
\label{sec:Simple4}

With the success of the dynamic heuristic in Section \ref{sec:Simple3}, another speculative issue needs to be addressed.
A possible issue, mentioned previously, is the inherent problems of connections through a swarm.
If an agent learns a new data point it may be unable to spread to the rest of the agents in the swarm, either because there is a physical lack of agents in the locality or those agents' memories are full.
There are three possible solutions to the memory saturation.
Agents repeat duplication requests if memory is full, priorities are used for data duplication or we keep the swarm at a state where information is spread equally around the swarm.

The latter being the solution explored in this project.
This solution is inherently worse than the priority solution, because the swarm can become oversaturated with duplicates.
A combination of the two solutions would be optimal, to reduce cases of oversaturation.
The author focuses solely on the swarm distributing data points equally, as a proof of concept.
The concept is the same as a migration from “SKUTE” \cite{Distributed Storage}.

Inherently we don’t want to limit the speed at which data can be migrated, for example an agent with oversaturated memory meets an agent with no memory used, ideally both walk away with equal memory load.
This will inherently increase the instability of the swarm, therefore, it’s a trade off.

The migration heuristic is a \textbf{AND} of the heuristic described in Section \ref{sec:Simple2} and whether the proposed agent's available space is significantly lower than the originating agent’s.
A pseudo code example can be seen in Algorithm \ref{Agent_Control_Loop4}.


\section{Neural Network Heuristic}
\label{sec:Simple5}

Results from the handcrafted heuristics show them to be adequate for solving the problem defined, however, they are far from the theoretical best solution. 
The problem faced with handcrafted designs is that they are not as expressive e.g. can’t inherently control for many edge cases or scenarios when compared to the highly expressive nature of a neural network. 
For example if we are far enough away from the datas desired location we don’t agent to suicde data unless there is another duplication in the locality. 
Currently the handcrafted heuristic would need extra conditions to satisfy that behaviour, whereas the neural network automatically can produce that behaviour, dependent on training. 
It would also mean that poorly selected thresholds for different implementations would not be as problematic, as long as training is undertaken properly. 
The design is as follows; for each run of a simulation a single neural network model is used on all agents.

\begin{figure}[htb]
\label{fig:Neural network}
\begin{center}
\centering
\includegraphics[height=5cm]{"./ExplanationImgs/NN.png"}
\caption{Neural network design - Thresholded argmax output}
\end{center}
\end{figure}

\begin{equation}
input = \begin{bmatrix} \frac{\psi_{app}}{\psi_{tot}} & \frac{n}{50} & r & \frac{s_{self}}{s_{loc}} & \frac{d}{\sqrt{8}} & \frac{\theta_{sui}}{1000} & \frac{\theta_{rep}}{1000} & \frac{\theta_{mig}}{1000} \end{bmatrix}
\end{equation}

Where $\psi_{app}$ is approved duplications to the agent and $\psi_{tot}$ is total duplication requests sent to this agent, both being zeroed after the agent's step. 
$n$ is the number of agents in the locality, $r$ is the duplication ratio as described before. 
$s_{self}$ is space left in the agent's memory and $s_{loc}$ is average space in locality excluding this agent. 
$d$ is the distance to the data’s data point. 
$\theta$ is how many iterations since the last action of a specific type. 
The three outputs correspond to Suicide, Replication and Migration. 
We therefore argmax the output and then check whether it is above a threshold to trigger the action, in our case the threshold is $>0.05$. 
The lime nodes in Figure \ref{fig:Neural network} are LSTM nodes and damon nodes are Dense nodes.

This network was selected because of its small size, relatively quick simulation speed and fitness improvement. 
It’s likely a larger network would be better with more LSTM layers, however, training time would be significantly increased. 
Simulation speed is a concern because of using a genetic algorithm which involves running multiple simulations. 
We are using a genetic algorithm because of two reasons;
Firstly, it’s impossible to know the correct output at a specific time, so a gradient descendant algorithm is not viable. 
Secondly, the move is unable to give an effective reward so reinforcement learning is also not viable. 
Therefore the only way to judge a network's performance is to run a simulation and compute a fitness function over the entire run.

\begin{equation}
fitness = \frac{\sum_{i=0}^{z}{\big(max( \overline{d_{i}}) - min( \overline{d_{i}})\big)^{2} - \frac{\big( \overline{q}_{i} - \frac{N_{i}}{4} \big)^{2}}{100} } - \overline{ \varpi_{i} } - std( \overline{\gamma_{i}} )}{z}
\end{equation}

Where $z$ is the number of iterations run. 
$\overline{d}$ is each agent’s average distance to their duplicated data’s desired location.
$\overline{q}$ is the average duplications over all data points, and $N$ is global current active agents. 
$\overline{ \varpi }$ is the mean instability over all data points. 
$\overline{\gamma}$ is the spread of agent's used memory space.

Square terms were used to emphasize a property we wanted the algorithm to focus on e.g. maximum spread of data and each data point to be duplicated in a fourth of the swarms population. 
The fitness function would need to be changed for different characteristics you desired for the swarm.

The genetic algorithm is run for 287 iterations with a population size of 40 with a mating rate of 36, therefore 4 completely random agents are created per iteration. 
Mating selection is made by a probability distribution over the magnitudes of fitness min max normalized.
Mating occurs by picking two agents from the previous population and randomly selecting weights from both models.
Parent selection is a probabilistic model based on fitness values, MinMax normalized then set so all normalised fitness values sum to one.
This therefore means that agents with higher fitness are more likely to be picked.



%%%%%%%%%%%%%%%%%%%%%%

%%%% Analysis %%%%
\chapter{Analysis}
\label{cha:Analysis}

\begin{figure}[htb]
\label{fig:static_movement_non}
\begin{center}
\centering
\includegraphics[width=\linewidth]{"./Static_Heuristic/Static_Movement_non.png"}
\caption{Static Heuristic on semi\-static movement swarm, with non\-correlated failures}
\end{center}
\end{figure}

The simulation is a 2D representation of a flat surface where agents can move freely around.
Agents are randomly located on the surface within a square that is 75\% of the environment's area.
Then the closest agent to each defined datapoint will learn its location, once learned these agents cannot lose this specific datapoint.
Agents are homogenous, with a small connection radius around them.
The world is height and width of 2 and an agents connection radius is 0.25.
Agents are assumed to have perfect connections and each agent can simultaneously respond to incoming packets and send outbound packets.

Agents can have two different types of data, one being private and other public.
Private data is a record of a data point of which it has learnt directly.
This data cannot be deleted and will be prioritised over public data.
Public data is learnt from interactions with other agents and can be deleted.
Both types of data can be passed on to other agents in the form of public data.

A control loop runs for 10,000 iterations, where agents are threaded for a single step per iteration.
All tests will be an average of 5 simulations.
Data will also have a gaussian filter applied as to make the graphs readable, kernel of size 50.
An example of the results can be seen in Figure \ref{fig:static_movement_non}, and all subsections will be explained below.

"Duplicated Data”, is the amount of duplicates that are in the swarm of a specific data point, represented by the individual line.
The green area is standard deviation around the mean of all data points.

"Number of agents", as the name implies is the number of active agents over all five runs.
The purple line is mean over all runs and the green area is the standard deviation from the mean.

“Data Distance”, is the distance from a duplicate to its respective point.
The lines and green area are the same as before, and the yellow area is the range of results, e.g. Max and min.

“Instability”, is how many agents changed from having a duplicate to not or vice versa, per data point.

“Pub-Mem Spread”, is the amount of duplicates per agent.

Lastly, there is duplication density spread per data point.
This allows the visualization of how density in duplication changes across the physical distance of the swarm.
Where the yellower colours signify more duplications to the number of agents than in a blue area.
The red dot signifies the data’s point of interest.

We are ideally looking for a suitable amount of duplicated data with a close spread, no matter the starting location. 
The distance of data points to desired locations to have the widest range possible. 
Instability to be low in magnitude and not react heavily to certain changes in other factors and the spread of memory load to have the smallest range possible. 
In the visualisation section we should see a wide spread with a highly dense epicenter.


\section{Static Heursitic}
\label{sec:Simple2a}

Firstly, we check whether the solution in Section \ref{sec:Simple2} works as intended with different threshold values, as in Figure \ref{fig:changing}. 
Looking at Figure \ref{fig:Threshold_Changes}, the reader will see that partially correct behaviour is observed. 
Tests were performed with semi-static movement at $\text{Threshold}_{rep} = \begin{bmatrix} 0.7 & 0.9 \end{bmatrix}$ and $\text{Threshold}_{sui} = \begin{bmatrix} 0.4 & 0.5 \end{bmatrix}$. 
These values are extreme and thus will highlight defects in the proposed solution.

It is observed that values of higher replication thresholds causes the effectiveness of the suicide threashold to decrease. 
This is because the effective duplicate area has too few agents inside to make an effective skimming strategy to duplications. 

It is also observed that a too high replication threshold and a too low suicide threshold causes massive instability at the fringe of the normal replication boundary. 
This is because the solution doesn’t have a stable mapping, therefore switches between multiple optimum.

Both these observations show a flaw in the proposed design in the fact that the threshold values need to be perfectly chosen in order for the solution to be anywhere near effective in a real world scenario. 
This flaw will try to be combated in Section \ref{sec:Simple3}.

Now moving onto performance under ideal threshold conditions, Figures \ref{fig:static_movement_non} and \ref{fig:circle_movement_non}. 
We start by looking at non-correlated failures on both movement type swarms. 
The reader will see that the gradient of data duplications and loss of agents are fairly correlated, this is a good sign to show that the proposed heuristic is adapting to the environment as it changes, after the initial expansion phase. 
As expected the expansion phase takes longer in the circular movement swarm, as of the broken connection nature of the movement. 
Within the static movement swarm the number of duplications per data point seems to be preset compared to the circular movement. 
This signifies that the heuristic is relying upon external factors to balance the loads.

The external factor argument can also be brought up in both positional sections where the circular movement has further reach, as expected from the less cohesive nature of movement e.g. Less chained connections.

Stability in the circular network is very erratic and periodic in nature. 
The periodic nature of instability can be explained by the circular motion of the agents, all the agents that start facing outwards will all converge back into the swarm in a periodic manner, thus creating a periodic gain in instability. 
However even with this accounted for, the heuristic didn’t perform adequately as we would like the solution to be able to handle these external factors. 
We would also like for the magnitude of the stability to be decreased. 

In “Pub-Mem Spread” we can see there is a large disparity between agents levels of used memory. 
This is not effective when thinking about scaling of the swarm and leaves us a vulnerability. 
This is that if too much data is in a single area then the learned data might be cut off from the rest of the swarm, this will try to be solved in Section \ref{sec:Simple4}.

Moving to correlated failures, Figures \ref{fig:static_movement_con} and \ref{fig:circle_movement_con}. 
A correlated failure happens in the middle of the swarm at the 3000th iteration with a failure radius of 0.25 (Same as an agent's connection range). 

As the reader will see we are still suffering from the same problems as described before. 
A positive observation is made about the recovery of the duplication values, after the correlated failure. 
An interesting observation is the lime green data point in Figure \ref{fig:circle_movement_con}, where it seems to be struggling to get more duplicates. 
From repeated tests this seems to be an outlier, however, is shown for transparency. 
The author believes it might have been to do with random placements of agents, therefore meaning less agents being close to the data duplicate point, therefore minimizing its replication heuristic.

Another interesting observation in Figure \ref{fig:static_movement_con} “Data Distance” purple data point, is its reduction before the spike at the failure. 
This is expected, at the initial expansion phase the data will spread across the swarm quicker than the swarm moves to the center, therefore will slowly bring its data points closer to itself over time, this is exaggerated because the expansion has more directions to move. 
The opposite can be seen in other data points.

\section{Dynamic Heuristic}
\label{sec:Simple3a}

Following the same approach as in Section \ref{sec:Simple2a}, with the values $\alpha_{rep}$ = 15, $\beta_{rep}$ = 2, $\alpha_{sui}$ = 150, $\beta_{rep}$ = 3. 
$\psi+=50$ every time a duplication request is made to this agent and $\psi--$ every iteration till 0.
These are in accordance with the equations in Section \ref{sec:Simple3}.

Testing the threshold value changes, we can see that the spread is the same, however, the instability has been reduced significantly in magnitude. 
The aim of this heuristic was to try and solve the instability problem rather than just reduce it. 
As can be seen, the curves are nearly identical. 
Therefore suggesting that our solution might not behave in the predicted way. 
We look into this further with more results with good valued thresholds.

From Figures \ref{fig:circle_movement_con2} and \ref{fig:circle_movement_non2} compared against Section \ref{sec:Simple2a} we can see that the heuristic has significantly improved the stability of the external factors, and stopped its periodic nature. 
However, the change has induced instability when comparing Figure \ref{fig:static_movement_non2} to its former self. 
This indicates that the solution should only be used in cases where high external instability exists therefore the internal instability increase is worth it.

An alarming observation is made in Figure \ref{fig:circle_movement_con2} where the increase in duplicates do not seem to slow down. 
This could lead to over saturation of duplications. 
The logical explanation for this behaviour is due to the movement of the swarm, as Figure \ref{fig:static_movement_con2} doesn’t share the same behaviour. 
This is most likely caused by agents breaking apart from the swarm, therefore leading to less suicides of duplicates.

When comparing all the results of the dynamic heuristic versus the static heuristic, we see a new tendency in the duplication density spread per data point section. 
The tendency is to have higher duplication densities to the side of the map. 
This is most prominent in the circular motion swarms. 
These results are misleading into believing that there are a lot of duplications in that area. 
On closer inspection of the results data it was visible that these highly dense areas were caused by a few agents with duplicates, due to the minimal size in agents the density will appear large in size even though there is only one or two duplicates there.  

An interesting observation about static-movement of non-correlated failures is that the duplicates tend to have varying levels of duplicates for different data points, compared to any other test. 
Mentioned in Section \ref{sec:Simple2a}, the cause rather than being an outlier or suffocation from other duplicates, it is now believed to be inherent with the movement of the swarm. 
As the agents gather around the middle they averagly get further away from there data points, in turn making it less likely to replicate and more likely to suicide. 
This can also explain the neatly spread out duplicate lines in static-movement correlated failure tests.

\section{Dynamic Heursitic with Migration}
\label{sec:Simple4a}

The new method proposed in Section \ref{sec:Simple4} was created to promote positive load sharing between the agents. 
Figures \ref{fig:static_movement_non3} and \ref{fig:static_movement_con3} both show this positive affect at the cost of instability. 
This internal instability is created by the movement of migrating data points, so is to be expected. 
We can also see that the method is trying to do the same in the circular movement swarms. 
However, it lacks actual performance with still the same costs to internal instability. 
From further investigation the cause was found to be the disconnected nature of movement in the swarm, agents have their own subsection of the swarm where they are roughly equal globally they are not. 
The semi-static movement handles this better because they are all drawn to the middle, if this was not the case then we would see similar results, due to the sub swarm nature of the movement.

In the density duplication spread section we can see that the new method significantly spreads data further than before, especially in semi-static movement cases. 
This shows that the new method is more torrent to larger correlated failures than previously proposed methods. 
This characteristic is more inline with the best conceivable solution to the problem defined in Section \ref{sec:Problem}. 
However, the increase in instability is an unwelcome sight.

Figure \ref{fig:circle_movement_con3} continues the uptrend mentioned in Section \ref{sec:Simple3a}. 
This shows that this behaviour is most likely not coincidental and is as mentioned previously.

The changes made to convert the dynamic heuristic to using migrations were intended to be a mild improvement without any significant side effects. 
However, even though the behaviors are similar, the use cases for each differ dramatically. 
This will be talked about in Section \ref{sec:conc}.

\section{Neural Network Heuristic}
\label{sec:Simple5a}

\begin{figure}[htb]
\label{fig:FitnessGA}
\begin{center}
\centering
\includegraphics[height=5cm]{"./GA_max_fitness_0.03_gradient.png"}
\caption{Genetic Algorithm fitness over generation}
\end{center}
\end{figure}

The results of the genetic algorithm described in Section \ref{sec:Simple5} are disappointing.
Initially the fitness on average was increasing and from running two separate tests seemed to have an improvement in action based performance.
However, after a lot more generations it became apparent that the solution was not improving effectively.

Figure \ref{fig:FitnessGA} shows an improvement with a gradient of 0.03.
However, this is max fitness of said generation.
These results indicate that there is a problem with either the design of the solution or implementation of the genetic algorithm.
We therefore run a test as shown in Figure \ref{fig:Failed_GA} to find out some more information.
Due to time restraints on training and poor performance the genetic algorithm was only trained for semi-static motion with non-correlated failures.

The results are not promising, other than nearer the end from about the 8000 iterations mark, where our duplicated data fits quite well to the target of a quarter of the population.

A factor that could have led to the failure of the genetic algorithms learning is low population size, restricted by training time and hardware.
Another limitation could be the mating selection allowing for worse agents to reproduce.
A better solution would be to have a top number of agents be able to reproduce and have a slightly larger mutated percentage of the population.
Running along these lines, the mutated agents relied on Tensor Flow's clone feature which assigns biases to zeros and uses “glorot\_uniform” for weights.
These values could have been too small in the weights to get past the 0.05 threshold and we could’ve lost expressive power from not allowing biases.
I believe one of the biggest contributions to the slow learning rate is large variations in the simulation environment, meaning that a model that was good last round might perform significantly worse in the next.
The author believed that this would have been averaged out overtime due to better models performing better on average.
However, it didn’t act as expected and made the genetic algorithm essentially a bad random search.
An improvement on this design would be to have the model run for multiple simulations in order to get a good indication of average performance or to have trained on only certain simulations. Then introduce random simulations in order for the agent to learn a partially overfitted strategy then unlearn slightly to fit other scenarios.
The first was not chosen because of computation time and second because of preliminary tests showing good results from the used design.

The model in and of itself could have been flawed in that it could be too large in input size for the length of time allowed for training.
To restrict the size of the input we could have reused functions from previous sections in order to nudge the neural network to learn faster, however, this would have lost us potential expressive power.
Another interesting proposition is to have the neural network produce the dynamic thresholds.
This would restrict the neural networks effectiveness, however, would ensure correct average behaviour and could possibly lead to possible gradient descendant learning using a mapping of the fitness function to a predicted value of where we want each threshold to be at certain times.



%%%%%%%%%%%%%%

%%%% Conclusion %%%%
\chapter{Conclusion}
\label{cha:conclusion}

\section{Conclusion}
\label{sec:conc}

//Need to talk more about the genetic algorithm stuff possibly in the anylisis section

Handcrafted algorithms proposed in Sections \ref{sec:Simple2}, \ref{sec:Simple3}, \ref{sec:Simple4} solve the problem proposed in Section \ref{sec:Problem}, with varying degrees of effectiveness and behaviour. 
When comparing them to a theoretical hybrid solution, we see obvious flaws, partially due to the nature of a fully homogeneous approach. 
In a real world application these approaches would not be as viable as the alternative, unless under very specific circumstances. 
These circumstances include, tight power consumption limits, large population swarms and high natural instability in connections. 
The method proposed in Section \ref{sec:Simple5} was a fail, for reasons described in Section \ref{sec:Simple5a}.

The method proposed in Section \ref{sec:Simple2}, shows to be effective at combating the problem, however, it lacks multiple characteristics needed for real world applications. 
We saw promising results with duplication spread in more volatile movement swarms with both correlated and non-correlated failures being handled appropriately. 
Behaviour is semi-static movement was not desirable, had an over reliance on correct threshold values and didn’t have tolerance for large correlated failures.

An updated version of the method was proposed in Section \ref{sec:Simple3} in order to combat some of these downfalls. 
The main target of change was instability of the system, this is where agents would keep replicating and suiciding data at the fringes of the heuristic boundary, occurring with a badly picked suicide threashold value. 
To combat this effect we used dynamic thresholds in order to slow the instability. 
This was done by using a time based slow on suicides and a local instability slow on replications. 
The combination of which would give us fast growth but a slow release of duplicated data, therefore hopefully finding stable solutions. 
These additions significantly improved characteristics of stability especially in naturally volatile swarms, e.g. Circular movement. 
We can see that instability issues were not solved by this method, but reduced in magnitude. 
The nature of the method ment that we increased internal instability but could significantly reduce external instability, so it would be more effective in different swarm scenarios. 
However, always out performed the previous proposed method from Section \ref{sec:Simple2}.

The additions proposed in Section \ref{sec:Simple4} are the most controversial in terms of use case. 
This is because the method completes the objective of spreading memory load over the swarm at the cost of higher instability. 
As a byproduct of the migration action, the method has more tolerance towards larger correlated failures. 
However, the amount of duplications seems to be affected more by loss of agents and memory spread is less affected in volatile swarms.

The proposed solutions assume that all data is highly important and that all agents near a data point should know its data. 
This makes these solutions harder to adapt to other situations where this feature is less needed. 
An example of this situation is large sensor swarm networks, where it might be good to have a duplication density change over the network but close to the data point it's not necessary for all sensor agents to know the information. 
A future example of this kind of use is moonquake detection, agents close to the moonquake epicenter wouldn’t need to know there was one coming because they wouldn’t have time to react, but agents within the damage radius that have time could strap themselves to the ground in order to not acquire damage. 

The project achieved two handcrafted solutions to the problem proposed, both with different use cases. 
If improvements were made from the suggestions made in Section \ref{sec:further} then I believe that these solutions could be very successful both in adaptability and performance, even when compared to a theoretical hybrid approach.

\section{Futher Improvements}
\label{sec:further}

There are a bunch of improvements that could be made in order to improve the performance of the suggested designs. 
Either computationally or methodologically.
Looking at methodology there are two design changes that could drastically improve characteristics of the algorithms. 
One is to allow for message hopping between agents in order to increase symbolic locality size, this would in turn give agents wider knowledge of the global swarm, however, would increase computation time and power draw per agent. 
The second is moving to a hybrid control which would allow for a more deterministic policy, however, gaining the downsides both of message hoping and problems described in Section \ref{sec:Robotics}.

Keeping with the same methodology we can reduce power consumption from messaging, however, could lead to erroneous results. 
Rather than each agent asking a question and awaiting a response from the locality, therefore meaning that each agent has to respond to every agent in it’s locality. 
Instead at the start of step per agent, they broadcast their relevant information. 
Agent’s in the locality then update their internal tables of the agents in the locality, therefore computation time is decreased because we have less IO time. 
Tables would need to release an agent's information if they haven’t broadcast in a while in order to detect that they are out of the locality. 
This therefore leads to a problem of possible executing off old information either from the agent running slower or out of locality.

With current proposed solutions we lack control for larger correlated failures. 
The handcrafted heuristics only sum together certain values and do a comparison on the output value, rather than making different decisions based on the values of each characteristic like the neural network can. 
This means that we get a linear behaviour, therefore not having cases that could help with increasing max distance of duplicate data. 
The nonlinear nature of the neural network will improve the chances of being able to change heuristic behaviour when certain values cross certain thresholds. 
This behaviour would be trivial to implement in a hybrid network, e.g. make sure at least two duplicates are as far away from their data point as possible. 
We would also have a higher guarantee that the data wouldn’t be lost because of the global view of the hybrid approach.

Currently the effective storage of the swarm is far less than the amount of memory the swarm has as a whole. 
A priority system could be used in order to insure a larger practical collective memory size compared to the smaller size current proposed heuristics provide. 
To make the priority system even more effective if an agent needs to lose data in order to learn a higher priority piece of data, said data could be migrated to other agents in its vicinity to make room for the higher priority data. 
Running along the same line as a priority system, a scheduler would be an effective way to handle the scalability of storage size per agent.


%%%%%%%%%%%%%%%%%%%


\appendix
\chapter{Code apendix}

\begin{algorithm}
\caption{Main Control Loop}
\label{Agent_Control_Loop1}
\begin{algorithmic}[1]
\Procedure{Step}{}
\State \text{move()}
\State
\If{Learned of new data point}
\State \text{Replicate new data point to locallity}
\State \Return True
\EndIf
\State
\State $d \gets \text{Euclidean distance to data current data point}$
\State $r \gets \text{(local) Duplicates on agents / Number of agents}$
\State $s \gets \text{(local) Average space available / Max public memory}$
\State
\State Replace with insert of choosen heuristic
\State
\If{ $h_{rep}$ (\text{Equation} \ref{eq:10}) $> \text{Threshold}_{rep}$}
\State \text{Replicate current data point to locallity}
\EndIf
\State
\If{$h_{sui}$ (\text{Equation} \ref{eq:10}) $> \text{Threshold}_{sui}$}
\State \text{Suicide current data point}
\EndIf
\State
\State \text{Iterate to next public data point}
\State
\State \Return True
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Static Heuristic Agent - Insert}
\label{Agent_Control_Loop2}
\begin{algorithmic}[1]
\State $X_{rep}, X_{sui} \gets $\text{Equation} \ref{eq:static_vals2}
\State $W_{rep}, W_{sui} \gets $\text{Equation} \ref{eq:static_vals1}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Dynamic Heuristic Agent - Insert}
\label{Agent_Control_Loop3}
\begin{algorithmic}[1]
\State $\theta \gets \text{Iterations since last suicide}$
\State $\psi \gets \text{Internal stability}$
\State $\lambda_{rep} \gets \text{Equation} \ref{eq:1}$
\State $\lambda_{sui}  \gets \text{Equation} \ref{eq:2}$
\State $X_{rep}, W_{rep} \gets $\text{Equation} \ref{eq:100}
\State $X_{sui}, W_{sui} \gets $\text{Equation} \ref{eq:101}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Dynamic Heuristic Agent With Migration - Insert}
\label{Agent_Control_Loop4}
\begin{algorithmic}[1]
\State $\theta \gets \text{Iterations since last suicide}$
\State $\psi \gets \text{Internal stability}$
\State $\lambda_{rep} \gets \text{Equation} \ref{eq:1}$
\State $\lambda_{sui}  \gets \text{Equation} \ref{eq:2}$
\State $X_{rep}, W_{rep} \gets $\text{Equation} \ref{eq:100}
\State $X_{sui}, W_{sui} \gets $\text{Equation} \ref{eq:101}
\State
\State $SX_{rep} \gets $\text{Equation} \ref{eq:static_vals2}
\State $SW_{rep} \gets $\text{Equation} \ref{eq:static_vals1}
\State
\State $\delta \gets$ \text{Max avalibale space - Our avaliable space}
\State
\If{ $h_{rep}(SX_{rep},SW_{rep}) $ (\text{Equation} \ref{eq:10}) $> \text{Threshold}_{rep} \text{ and } \delta > 1$}
\State \text{Duplicate item to target agent}
\State
\If{Successful}
\State \text {Suicide current data point}
\State \Return True
\EndIf
\EndIf
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{Semi-Static movement}
\label{semistaticmove}
\begin{algorithmic}[1]
\Procedure{Move}{}
\State $dirforce \gets \text{Define vectors from other agents to self}$
\State $forces \gets \text{$dirforce$ with magnitudes $($0.24 $-$ Current magnitude$)$}$
\State
\State \text{Apply small force to center of map}
\State
\State $face \gets \text{Angle of resultant force on $forces$}$
\State \text{Point at angle $face$ and move forward by 0.0002}
\State
\State \Return True
\EndProcedure
\end{algorithmic}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Results apendix}

\begin{figure}[htb]
\label{fig:Threshold_Changes}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Static_Heuristic/Threshold_Changes.png"}
\caption{Static Heuristic on semi\-static movement swarm, with threshold changes}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:static_movement_con}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Static_Heuristic/Static_Movement_concurrent.png"}
\caption{Static Heuristic on semi\-static movement swarm, with correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:circle_movement_non}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Static_Heuristic/Circle_movement_non.png"}
\caption{Static Heuristic on circular movement swarm, with non\-correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:circle_movement_con}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Static_Heuristic/Circle_movement_concurrent.png"}
\caption{Static Heuristic on circular movement swarm, with correlated failures}
\end{center}
\end{figure}

%%%%

\begin{figure}[htb]
\label{fig:Threshold_Changes2}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Heuristic/Thresholdchanges.png"}
\caption{Dynamic Heuristic on semi\-static movement swarm, with threshold changes}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:static_movement_non2}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Heuristic/Static_Move_non.png"}
\caption{Dynamic Heuristic on semi\-static movement swarm, with non\-correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:static_movement_con2}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Heuristic/Static_Move_con.png"}
\caption{Dynamic Heuristic on semi\-static movement swarm, with correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:circle_movement_non2}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Heuristic/Cicrle_Move_non.png"}
\caption{Dynamic Heuristic on circular movement swarm, with non\-correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:circle_movement_con2}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Heuristic/Circle_Move_con.png"}
\caption{Dynamic Heuristic on circular movement swarm, with correlated failures}
\end{center}
\end{figure}

%%%%

\begin{figure}[htb]
\label{fig:static_movement_non3}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Migration/Static_Move_non.png"}
\caption{Dynamic Heuristic with Migration on semi\-static movement swarm, with non\-correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:static_movement_con3}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Migration/Static_Move_con.png"}
\caption{Dynamic Heuristic with Migration on semi\-static movement swarm, with correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:circle_movement_non3}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Migration/Circle_Move_non2.png"}
\caption{Dynamic Heuristic with Migration on circular movement swarm, with non\-correlated failures}
\end{center}
\end{figure}

\begin{figure}[htb]
\label{fig:circle_movement_con3}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Dynamic_Migration/Circle_Move_con.png"}
\caption{Dynamic Heuristic with Migration on circular movement swarm, with correlated failures}
\end{center}
\end{figure}

%%%%

\begin{figure}[htb]
\label{fig:Failed_GA}
\begin{center}
\centering
\includegraphics[height=7cm]{"./Failed_GA.png"}
\caption{Discouraging results from Neural Network Heuristic, semi\-static movement and non\-correlated failures}
\end{center}
\end{figure}

%%%%




\begin{thebibliography}{100}
\bibitem{Swarm robotics reviewed} 
J. C. Barca and Y. A. Sekercioglu, “Swarm robotics reviewed,” Robotica, vol. 31, no. 3, pp. 345–359, 2013.

\bibitem{Cognitive maps mine detection}
V. Kumar and F. Sahin, "Cognitive maps in swarm robots for the mine detection application," SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483), Washington, DC, 2003, pp. 3364-3369 vol.4, doi: 10.1109/ICSMC.2003.1244409.

\bibitem{Triggered Memory dynamic enviroments}
H. Wang, D. Wang and S. Yang, “Triggered Memory-Based Swarm Optimization in Dynamic Environments,” in Applications of Evolutionary Computing, M. Giacobini, Ed. Berlin, Germany: Springer-Verlag Berlin and Heidelberg GmbH \& Co. K, 2007, pp. 637–646.

\bibitem{Probabalitic automata foraging robots}
D. A. Lima and G. M. B. Oliveira, "A probabilistic cellular automata ant memory model for a swarm of foraging robots," 2016 14th International Conference on Control, Automation, Robotics and Vision (ICARCV), Phuket, 2016, pp. 1-6, doi: 10.1109/ICARCV.2016.7838615.

\bibitem{Swarm intellegiegence}
E. Bonabeau, M. Dorigo, and G. Theraulaz, Swarm Intelligence: From Natural to Artificial Systems. Cary, NC, USA: Oxford University Press, 1999.

\bibitem{Dynamic raid hybrid}
L. Xiang, Y. Xu, J. Lui, Q. Chang, Y. Pan, and R. Li, ‘A Hybrid Approach to Failed Disk Recovery Using RAID-6 Codes: Algorithms and Performance Evaluation’, Association for Computing Machinery, vol. 7, p. 11, 2011

\bibitem{CPU speed}
C. Mims, ‘Why CPUs Aren’t Getting Any Faster’, MIT Technology Review, 2010. [Online]. Available: https://www.technologyreview.com/2010/10/12/199966/why-cpus-arent-getting-any-faster/. [Accessed: 01-Dec-2020].

\bibitem{Raid parity}
U. Troppens, W. Müller‐Friedt, R. Wolafka, R. Erkens, and N. Haustein, ‘Appendix A: Proof of Calculation of the Parity Block of RAID 4 and 5’, in Storage Networks Explained: Basics and Application of Fibre Channel SAN, NAS, ISCSI, InfiniBand and FCoE, U. Troppens, Ed. Chichester: Wiley United Kingdom, 2009, pp. 535–536.

\bibitem{Avalability storage}
J. Liu and H. Shen, "A Low-Cost Multi-failure Resilient Replication Scheme for High Data Availability in Cloud Storage," 2016 IEEE 23rd International Conference on High Performance Computing (HiPC), Hyderabad, 2016, pp. 242-251, doi: 10.1109/HiPC.2016.036.

\bibitem{Distributed Storage}
N. Bonvin, T. G. Papaioannou, and K. Aberer, A Self-Organized, Fault-Tolerant and Scalable Replication Scheme for Cloud Storage. New York, NY, USA: Association of Computing Machinery, 2010.

\bibitem{LSA}
Legal Services Act. 2007.

\bibitem{Patent}
A. Prahlad, M. S. Muller, R. Kottomtharayil, S. Kavuri, P. Gokhale, and M. Vijayan, ‘Cloud gateway system for managing data storage to cloud storage sites’, 20100333116A1, 2010.

\bibitem{Scheme changes}
B. Czejdo, K. Messa, T. Morzy, M. Morzy, and J. Czejdo, ‘Data Warehouses with Dynamically Changing Schemas and Data Sources’, in Proceedings of the 3rd International Economic Congress, Opportunieties of Change, Sopot, Poland, 2003, p. 10.

\bibitem{Key-Value}
‘Key-Value Scores Explained’, HazelCast. [Online]. Available: https://hazelcast.com/glossary/key-value-store/. [Accessed: 02-Dec-2020].

\bibitem{Paxos}
L. Lamport, ‘The Part-Time Parliament’, in Concurrency: The Works of Leslie Lamport, New York, NY, USA: Association of Computing Machinery, 2019, pp. 277–317.

\bibitem{Quorum}
D. Agrawal and A. E. Abbadi. The tree quorum protocol: An efficient approach for managing replicated data. In VLDB’90: Proc. of the 16th International Conference on Very Large Data Bases, pages 243–254, Brisbane, Queensland,Australia, 1990.

\bibitem{RAID levels}
S. Lynn, ‘RAID Levels Explained’, PC Mag, 2014. [Online]. Available: https://uk.pcmag.com/storage/7917/raid-levels-explained. [Accessed: 06-Dec-2020].

\bibitem{HiveMind}
J. Hu et al., Eds., HiveMind: A Scalable and Serverless Coordination Control Platform for UAV Swarms. ArXiv, 2020.

\bibitem{blockchainandSwarm}
D. Calvaresi, A. Dubovitskaya, J. P. Calbimonte, K. Taveter, and M. Schumacher, Multi-Agent Systems and Blockchain: Results from a Systematic Literature Review. Cham, Switzerland: Springer International Publishing, 2018.

\bibitem{Space exploration}
L. A. Nguyen, T. L. Harman and C. Fairchild, "Swarmathon: A Swarm Robotics Experiment For Future Space Exploration," 2019 IEEE International Symposium on Measurement and Control in Robotics (ISMCR), Houston, TX, USA, 2019, pp. B1-3-1-B1-3-4, doi: 10.1109/ISMCR47492.2019.8955661.

\bibitem{UAV}
M. Y. Arafat and S. Moh, "Localization and Clustering Based on Swarm Intelligence in UAV Networks for Emergency Communications," in IEEE Internet of Things Journal, vol. 6, no. 5, pp. 8958-8976, Oct. 2019, doi: 10.1109/JIOT.2019.2925567.

\bibitem{Ant communication}
D. Jackson and F. Ratnieks, ‘Communication in ants,’Current Biology,vol. 16, pp. 570–574, 2006.

\bibitem{Boids}
C. W. Reynolds, Flocks, Herds, and Schools: A Distributed Behavioral Model. ACM, 1987.

\end{thebibliography}



\end{document}
